import { loadConfig, isParserV2 } from '../config';
import { removeRepeatedFooters, normalizeNoData, normalizeEOL, healOCRBreaks, advancedRepetitiveContentRemoval, normalizeUnicodeAndPunct, filterHeadersAndFooters as filterHeadersAndFootersLLM } from '../msds/cleanup';
import * as fs from 'fs';
import * as path from 'path';
import { processMsds } from '../msds-new/pipeline';
import { splitSectionsByNumber } from '../msds/sections';
import {
  OCRWord,
  clusterWordsToLines,
  stripRecurringHeaderFooter,
  linesToText,
  stripRecurringTopBottomByPage,
  normalizeUnicodeAndPunct as layoutNormalizeUnicodeAndPunct
} from '../../src/ocr/layout-clean';

/** ===========================
 *  Page-aware header/footer cleaner (vendor-agnostic)
 *  =========================== */

// Known header/footer patterns library
const KNOWN_HEADER_FOOTER_PATTERNS = {
  // Page numbering patterns
  pageNumbers: [
    /^Page\s+\d+\s+of\s+\d+$/i,
    /^Page\s+\d+$/i,
    /^\d+\s*$/,
    /^-\s*\d+\s*-$/,
    /^\d+\s*\/\s*\d+$/
  ],
  
  // Document titles and headers
  documentTitles: [
    /^Material\s+Safety\s+Data\s+Sheet$/i,
    /^Safety\s+Data\s+Sheet$/i,
    /^MSDS$/i,
    /^SDS$/i,
    /^Product\s+Information\s+Sheet$/i
  ],
  
  // Company information patterns
  companyInfo: [
    /^¬©\s*\d{4}/i, // Copyright
    /^Copyright\s+\d{4}/i,
    /^Confidential$/i,
    /^Proprietary$/i,
    /^All\s+Rights\s+Reserved$/i,
    /^Internal\s+Use\s+Only$/i
  ],
  
  // Address patterns
  addresses: [
    /^\d+\s+[A-Za-z\s]+(?:Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Drive|Dr|Lane|Ln|Way|Circle|Cir|Court|Ct)/i,
    /^[A-Za-z\s]+,\s*[A-Z]{2}\s+\d{5}(?:-\d{4})?$/i, // City, State ZIP
    /^[A-Za-z\s]+,\s*[A-Za-z\s]+,\s*\d{5}(?:-\d{4})?$/i, // City, State, ZIP
    /^Tel[ephone]*:\s*[\d\-\+\(\)\s]+$/i,
    /^Fax:\s*[\d\-\+\(\)\s]+$/i,
    /^Email:\s*[\w\.-]+@[\w\.-]+\.\w+$/i,
    /^Web[site]*:\s*https?:\/\/[\w\.-]+/i
  ],
  
  // Legal disclaimers
  disclaimers: [
    /^This\s+information\s+is\s+believed\s+to\s+be\s+accurate/i,
    /^The\s+information\s+contained\s+herein/i,
    /^No\s+warranty\s+is\s+made/i,
    /^Use\s+at\s+your\s+own\s+risk/i,
    /^For\s+professional\s+use\s+only/i
  ],
  
  // Section separators
  separators: [
    /^[-=_]{3,}$/, // Lines of dashes, underscores, equals
    /^[‚Ä¢\*\-]{3,}$/, // Bullet point lines
    /^[#]{3,}$/, // Hash lines
    /^[~]{3,}$/ // Tilde lines
  ],
  
  // All caps lines (likely headers)
  allCaps: [
    /^[A-Z\s]{10,}$/ // 10+ character all caps lines
  ]
};

// Function to load patterns from config file
function loadPatternsFromConfig(): typeof KNOWN_HEADER_FOOTER_PATTERNS {
  try {
    const configPath = path.join(__dirname, '../config/header-footer-patterns.json');
    
    if (fs.existsSync(configPath)) {
      const config = JSON.parse(fs.readFileSync(configPath, 'utf8'));
      const loadedPatterns: any = {};
      
      for (const [category, patterns] of Object.entries(config.patterns)) {
        if (Array.isArray(patterns)) {
          loadedPatterns[category] = patterns.map((pattern: string) => new RegExp(pattern, 'i'));
        }
      }
      
      console.log(`üìö Loaded ${Object.keys(loadedPatterns).length} pattern categories from config`);
      return loadedPatterns as typeof KNOWN_HEADER_FOOTER_PATTERNS;
    }
  } catch (error) {
    console.warn('‚ö†Ô∏è Failed to load patterns from config, using defaults:', error);
  }
  
  return KNOWN_HEADER_FOOTER_PATTERNS;
}

// Load patterns from config file
const PATTERNS = loadPatternsFromConfig();

// Function to check if a line matches known patterns
function matchesKnownPatterns(line: string): boolean {
  const patterns = Object.values(PATTERNS).flat();
  return patterns.some(pattern => pattern.test(line.trim()));
}

// Function to get pattern category for a line
function getPatternCategory(line: string): string | null {
  for (const [category, patterns] of Object.entries(PATTERNS)) {
    if (patterns.some(pattern => pattern.test(line.trim()))) {
      return category;
    }
  }
  return null;
}

/* =========================
   CONSOLIDATED MSDS PATCH
   ========================= */

// ---------- Light normalization just for parsing ----------
function _nfkcSoft(s: string): string {
  if (!s) return s;
  return s.normalize('NFKC')
    .replace(/\u00A0/g, ' ')
    .replace(/[\u200B\u200C\u200D\uFEFF]/g, '')
    .replace(/[ÔºöÔπïÔ∏∞]/g, ':')
    .replace(/[‚Äê‚Äì‚Äî‚Äï]/g, '-') // dash variants ‚Üí hyphen
    .replace(/[ \t]+\n/g, '\n')
    .replace(/[ \t]{2,}/g, ' ')
    .trim();
}

// ---------- Verbatim cleaning (no normalization) ----------
function preCleanVerbatim(s: string): string {
  return (s ?? '').replace(/\r\n?/g, '\n').trim();
}

// ---------- (Optional but recommended) pre-clean recurring PDF artifacts ----------
function preCleanParsingArtifacts(text: string): string {
  return _nfkcSoft(text)
    // common SDS footer/header crumbs that break section continuity:
    .replace(/^\s*Contd\.?\.?\s*(on|from)\s*page\s*\d+.*$/gim, '')
    .replace(/^\s*Date of (issue|revision).*$\n?/gim, '')
    .replace(/^\s*Version\s*\d+(\.\d+)?\s*.*$\n?/gim, '')
    .replace(/^\s*End of (Material Safety Data Sheet|SDS).*$\n?/gim, '')
    .replace(/^\s*Page\s*\d+\s*(of\s*\d+)?\s*.*$\n?/gim, '')
    .replace(/\n{3,}/g, '\n\n')
    .trim();
}

// ---------- Canonical titles (for stability) ----------
const CANON_16 = [
  'Identification of the material and supplier',
  'Hazards Identification',
  'Composition / Information on Ingredients',
  'First Aid Measures',
  'Firefighting Measures',
  'Accidental Release Measures',
  'Handling and Storage',
  'Exposure Controls / Personal Protection',
  'Physical and Chemical Properties',
  'Stability and Reactivity',
  'Toxicological Information',
  'Ecological Information',
  'Disposal Considerations',
  'Transport Information',
  'Regulatory Information',
  'Other Information',
];

function canonicalTitleFor(n: number) {
  return CANON_16[n - 1] || `Section ${n}`;
}

// ---------- Header detector + block capture (the new splitter) ----------

type ParsedSection = { number: number; title: string; content: string };

// Matches typical SDS headings at start of a line.
// Examples matched:
//  SECTION 1: Identification
//  Section 2 - Hazards Identification
//  3. Composition/Information on Ingredients
//  10 Stability and Reactivity
const HEADER_RX = new RegExp(
  String.raw`^` +                        // line start
  String.raw`\s*` +
  String.raw`(?:section\s+)?` +          // optional "Section" (must have space after)
  String.raw`(?<num>\d{1,2})` +          // 1..16
  String.raw`(?:\s*[-‚Äì‚Äî:)\]]\s*|\s+|\.(?!\d))` +  // delimiter: -, ‚Äî, :, ), ], space(s), or . (but not followed by digit)
  String.raw`(?<title>[^\n]{0,120})?` +  // optional title (rest of line)
  String.raw`$`,
  'gim'
);

export function splitSectionsByNumberV2(raw: string): ParsedSection[] {
  const text = preCleanParsingArtifacts(raw);

  // Find all heading matches with their indices
  const matches: Array<{start: number; end: number; num: number; title: string}> = [];
  let m: RegExpExecArray | null;
  while ((m = HEADER_RX.exec(text)) !== null) {
    const num = parseInt(m.groups?.num || '0', 10);
    if (!Number.isFinite(num) || num < 1 || num > 16) continue;
    
    // Guard: reject lines like "6.4 ..." as top-level sections
    const line = text.slice(m.index, m.index + m[0].length);
    if (/^\s*\d{1,2}\.\d+/.test(line)) {
      console.log(`üö´ Skipping subsection: ${line.trim()}`);
      continue;
    }
    
    // title may include trailing spaces / punctuation ‚Äì trim it
    const rawTitle = (m.groups?.title || '').trim();
    console.log(`‚úÖ Found section ${num}: "${rawTitle || 'No title'}"`);
    matches.push({ start: m.index, end: m.index + m[0].length, num, title: rawTitle });
  }

  if (matches.length === 0) {
    // fallback: all content becomes Section 1 if nothing matched
    return [{ number: 1, title: `Section 1 ‚Äî ${canonicalTitleFor(1)}`, content: text.trim() || 'Not available.' }];
  }

  // Sort by document position (safety)
  matches.sort((a, b) => a.start - b.start);

  // Build blocks: [header_i.end, header_{i+1}.start)
  // Use Map to handle duplicate sections by concatenation
  const sectionMap = new Map<number, { title: string; content: string }>();
  
  for (let i = 0; i < matches.length; i++) {
    const cur = matches[i];
    const next = matches[i + 1];

    const blockStart = cur.end;
    const blockEnd = next ? next.start : text.length;
    let content = text.slice(blockStart, blockEnd);

    // tidy content block
    content = content
      .replace(/^\s+|\s+$/g, '')
      .replace(/\n{3,}/g, '\n\n');

    // resolve title: prefer canonical for stability; keep detected words if they look meaningful
    const detectedTitle = cur.title?.replace(/\s{2,}/g, ' ').trim() || '';
    const finalTitle =
      detectedTitle && /[A-Za-z]/.test(detectedTitle)
        ? `Section ${cur.num} ‚Äî ${canonicalTitleFor(cur.num)}`
        : `Section ${cur.num} ‚Äî ${canonicalTitleFor(cur.num)}`;

    const cleanContent = content.trim() || 'Not available.';
    
    // Merge duplicates by concatenation
    if (sectionMap.has(cur.num)) {
      const existing = sectionMap.get(cur.num)!;
      sectionMap.set(cur.num, {
        title: finalTitle, // use latest title
        content: existing.content + '\n\n' + cleanContent
      });
      console.log(`üîÑ Merged duplicate section ${cur.num}`);
    } else {
      sectionMap.set(cur.num, {
        title: finalTitle,
        content: cleanContent
      });
    }
  }
  
  // Convert Map to array
  const out: ParsedSection[] = Array.from(sectionMap.entries()).map(([num, data]) => ({
    number: num,
    title: data.title,
    content: data.content
  }));

  // Optional: ensure 1..16 presence (fill missing with empty content)
  const have = new Set(out.map(s => s.number));
  for (let n = 1; n <= 16; n++) {
    if (!have.has(n)) {
      out.push({ number: n, title: `Section ${n} ‚Äî ${canonicalTitleFor(n)}`, content: 'Not available.' });
    }
  }

  // Sort by number ascending
  out.sort((a, b) => a.number - b.number);
  return out;
}

// ---------- Canonical 16 keys mapping ----------
const TEMPLATE_KEYS = {
  1: '1. Identification of the material and supplier:',
  2: '2. Hazards Identification:',
  3: '3. Composition/Information on Ingredients:',
  4: '4. First Aid Measures:',
  5: '5. Firefighting Measures:',
  6: '6. Accidental Release Measures:',
  7: '7. Handling and Storage:',
  8: '8. Exposure Controls/Personal Protection:',
  9: '9. Physical and Chemical Properties:',
  10: '10. Stability and Reactivity:',
  11: '11. Toxicological Information:',
  12: '12. Ecological Information:',
  13: '13. Disposal Considerations:',
  14: '14. Transport Information:',
  15: '15. Regulatory Information:',
  16: '16. Other Information:'
};

// Build final object with exactly these 16 keys
function buildCanonical16Sections(sections: ParsedSection[]): Record<string, string> {
  const result: Record<string, string> = {};
  
  for (let i = 1; i <= 16; i++) {
    const section = sections.find(s => s.number === i);
    result[TEMPLATE_KEYS[i as keyof typeof TEMPLATE_KEYS]] = section?.content || 'Not available.';
  }
  
  return result;
}

/** Normalization: punctuation, units, LaTeX bits, ranges */
function normalizeForMsds(s: string): string {
  if (!s) return s;
  let out = s.normalize('NFKC')
    .replace(/[ÔºöÔπïÔ∏∞]/g, ':')
    .replace(/[Ôºå]/g, ',')
    .replace(/[Ôºà]/g, '(')
    .replace(/[Ôºâ]/g, ')')
    .replace(/[‚Äê‚Äì‚Äî‚Äï]/g, '-')           // dash variants ‚Üí hyphen
    .replace(/\u00A0/g, ' ')
    .replace(/[\u200B\u200C\u200D\uFEFF]/g, '')
    .replace(/[ \t]+\n/g, '\n')
    .replace(/[ \t]{2,}/g, ' ');

  // units & ranges
  out = out.replace(/‚ÑÉ/g, '¬∞C')
           .replace(/[~ÔΩû„ÄúÔπè]/g, '‚Äì')
           .replace(/\b(pH)\s*[:=]?\s*([0-9]+(?:\.[0-9]+)?)\s*[‚Äì-]\s*([0-9]+(?:\.[0-9]+)?)/gi, 'pH $2‚Äì$3');

  // LaTeX-ish
  out = out.replace(/\^\{\s*\}/g, '')
           .replace(/\\(?:left|right)\s*[\(\)\[\]\{\}]/g, '')
           .replace(/\\(?:quad|beta|mathrm)\{?([^}]*)\}?/gi, '$1')
           .replace(/\$+\s*([^$]+?)\s*\$+/g, '$1')
           .replace(/([A-Za-z])_+\{?(\d+)\}?/g, '$1$2')   // subscripts ‚Üí plain
           .replace(/\n{3,}/g, '\n\n')
           .trim();
  return out;
}

// Legacy function for backward compatibility
function nfkcNormalize(s: string): string {
  return normalizeForMsds(s);
}

/** Page-aware header/footer removal (keep first occurrence; protect facts) */

type PageSplit = { index: number; lines: string[] };

function fpLine(line: string): string {
  return line.toLowerCase()
    .replace(/\bhttps?:\/\/\S+/g, '')
    .replace(/\b\S+@\S+\.\w+\b/g, '')
    .replace(/\d+/g, '')
    .replace(/[^\w\s]+/g, ' ')
    .replace(/\s+/g, ' ')
    .trim();
}

function looksLikeMaterialFact(line: string): boolean {
  return /\bCAS\s*No?\.?\s*\d{2,7}-\d{2}-\d\b/i.test(line)
      || /\bUN\s*\d{3,5}\b/i.test(line)
      || /\bpH\b\s*[:=]?\s*\d/i.test(line)
      || /\d+\s*¬∞\s*C\b/i.test(line)
      || /\bEINECS\b|\bEC\b\s*\d+/i.test(line);
}

function splitIntoPages(raw: string): PageSplit[] {
  const norm = normalizeForMsds(raw);
  const chunks = norm.includes('\f') ? norm.split('\f') : norm.split(/\n{4,}/g);
  return chunks.map((t, i) => ({ index: i, lines: t.split(/\r?\n/).map(x => x.trim()).filter(Boolean) }));
}

function splitIntoPagesVerbatim(raw: string): PageSplit[] {
  // Use verbatim cleaning only - no normalization
  const cleaned = preCleanVerbatim(raw);
  const chunks = cleaned.includes('\f') ? cleaned.split('\f') : cleaned.split(/\n{4,}/g);
  return chunks.map((t, i) => ({ index: i, lines: t.split(/\r?\n/).map(x => x.trim()).filter(Boolean) }));
}

function removalRatio(before: string, after: string) {
  const b = (before.match(/\n/g)?.length ?? 0) + 1;
  const a = (after.match(/\n/g)?.length ?? 0) + 1;
  return (b - a) / Math.max(1, b);
}

function removePageRecurringHeadersAndFooters(raw: string, topN = 10, bottomN = 10): string {
  const pages = splitIntoPages(raw);
  if (!pages.length) return preCleanVerbatim(raw);

  const minRepeat = Math.max(2, Math.ceil(pages.length * 0.6)); // ‚â•60% of pages
  const minFpLen = 18;

  const topCounts = new Map<string, number>();
  const bottomCounts = new Map<string, number>();
  const topFPsByPage: string[][] = [];
  const bottomFPsByPage: string[][] = [];

  for (const p of pages) {
    const top = p.lines.slice(0, Math.min(topN, p.lines.length)).map(fpLine);
    const bottom = p.lines.slice(Math.max(0, p.lines.length - bottomN)).map(fpLine);
    topFPsByPage.push(top); bottomFPsByPage.push(bottom);
    for (const fp of top) topCounts.set(fp, (topCounts.get(fp) || 0) + 1);
    for (const fp of bottom) bottomCounts.set(fp, (bottomCounts.get(fp) || 0) + 1);
  }

  const dropTop = new Set(Array.from(topCounts.entries()).filter(([fp, c]) => fp && fp.length >= minFpLen && c >= minRepeat).map(([fp]) => fp));
  const dropBottom = new Set(Array.from(bottomCounts.entries()).filter(([fp, c]) => fp && fp.length >= minFpLen && c >= minRepeat).map(([fp]) => fp));

  console.log(`üßπ Header/Footer removal: Found ${dropTop.size} top patterns, ${dropBottom.size} bottom patterns to remove`);

  const firstSeen = new Set<string>();
  const cleanedPages: string[] = [];

  pages.forEach((page, pIdx) => {
    const L = page.lines.length;
    const topSet = new Set(topFPsByPage[pIdx]);
    const bottomSet = new Set(bottomFPsByPage[pIdx]);
    const keep: string[] = [];

    for (let i = 0; i < L; i++) {
      const line = page.lines[i];
      const fp = fpLine(line);
      const topCand = i < Math.min(topN, L) && topSet.has(fp);
      const botCand = i >= Math.max(0, L - bottomN) && bottomSet.has(fp);

      let drop = false;
      if ((topCand && dropTop.has(fp)) || (botCand && dropBottom.has(fp))) {
        if (!looksLikeMaterialFact(line)) {
          if (!firstSeen.has(fp)) { 
            firstSeen.add(fp); 
            drop = false; // keep first occurrence (for Sec 1)
            console.log(`üìå Keeping first occurrence: ${line.trim().substring(0, 50)}...`);
          } else { 
            drop = true;
            console.log(`üóëÔ∏è Removing repeated: ${line.trim().substring(0, 50)}...`);
          }
        }
      }
      if (!drop) keep.push(line);
    }
    cleanedPages.push(keep.join('\n').trim());
  });

  const joined = cleanedPages.join('\n\n').replace(/\n{3,}/g, '\n\n').trim();
  const originalLength = (raw.match(/\n/g)?.length ?? 0) + 1;
  const cleanedLength = (joined.match(/\n/g)?.length ?? 0) + 1;
  const removalRatio = (originalLength - cleanedLength) / originalLength;
  
  if (removalRatio > 0.30) {
    console.warn(`‚ö†Ô∏è Header/Footer removal too aggressive (${Math.round(removalRatio * 100)}% removed); reverting to verbatim text.`);
    return preCleanVerbatim(raw);
  }
  
  console.log(`‚úÖ Header/Footer removal: ${Math.round(removalRatio * 100)}% of lines removed`);
  return joined;
}

/**
 * Normalize section titles and merge duplicates per section with conservative contact-line filter
 */
export function normalizeSectionTitles(
  sections: Array<{ number: number; title: string; content: string }>
): Array<{ number: number; title: string; content: string }> {
  console.log('üìã Normalizing section titles...');
  
  const normalizedSections = sections.map(section => {
    const originalTitle = section.title;
    
    // Normalize section title
    let normalizedTitle = normalizeSectionTitle(originalTitle);
    
    // Apply conservative contact-line filter inside merge
    normalizedTitle = applyConservativeContactLineFilter(normalizedTitle);
    
    console.log(`üìã Section ${section.number}: "${originalTitle}" -> "${normalizedTitle}"`);
    
    return {
      ...section,
      title: normalizedTitle
    };
  });

  // Merge duplicate sections by title
  const mergedSections = mergeDuplicateSections(normalizedSections);
  
  console.log(`üìã Section normalization complete: ${sections.length} -> ${mergedSections.length} sections`);
  
  return mergedSections;
}

function normalizeSectionTitle(title: string): string {
  if (!title) return title;
  
  let normalized = title.trim();
  
  // Remove common OCR artifacts
  normalized = normalized
    .replace(/^[^\w\d]*/, '') // Remove leading non-alphanumeric
    .replace(/[^\w\d]*$/, '') // Remove trailing non-alphanumeric
    .replace(/\s+/g, ' ') // Normalize whitespace
    .trim();
  
  // Standardize common section title variations
  const titleMappings: Record<string, string> = {
    // Section 1 variations
    'identification': 'Identification',
    'product identification': 'Identification',
    'chemical identification': 'Identification',
    'substance identification': 'Identification',
    
    // Section 2 variations
    'hazards identification': 'Hazards Identification',
    'hazard identification': 'Hazards Identification',
    'hazards': 'Hazards Identification',
    
    // Section 3 variations
    'composition information': 'Composition/Information on Ingredients',
    'composition': 'Composition/Information on Ingredients',
    'ingredients': 'Composition/Information on Ingredients',
    'chemical composition': 'Composition/Information on Ingredients',
    
    // Section 8 variations
    'exposure controls': 'Exposure Controls/Personal Protection',
    'personal protection': 'Exposure Controls/Personal Protection',
    'exposure limits': 'Exposure Controls/Personal Protection',
    
    // Section 9 variations
    'physical properties': 'Physical and Chemical Properties',
    'chemical properties': 'Physical and Chemical Properties',
    'physical chemical properties': 'Physical and Chemical Properties',
    
    // Section 12 variations
    'ecological information': 'Ecological Information',
    'environmental information': 'Ecological Information',
    'environmental hazards': 'Ecological Information',
    
    // Section 15 variations
    'regulatory information': 'Regulatory Information',
    'regulatory data': 'Regulatory Information',
    'regulatory': 'Regulatory Information'
  };
  
  const lowerTitle = normalized.toLowerCase();
  for (const [key, value] of Object.entries(titleMappings)) {
    if (lowerTitle.includes(key)) {
      normalized = value;
      break;
    }
  }
  
  return normalized;
}

function applyConservativeContactLineFilter(title: string): string {
  // Conservative filter to remove obvious contact information from titles
  const contactPatterns = [
    /tel[ephone]*:\s*[\d\-\+\(\)\s]+/gi,
    /fax:\s*[\d\-\+\(\)\s]+/gi,
    /email:\s*[\w\.-]+@[\w\.-]+\.\w+/gi,
    /web[site]*:\s*https?:\/\/[\w\.-]+/gi,
    /phone:\s*[\d\-\+\(\)\s]+/gi,
    /address:\s*[^\n]+/gi
  ];
  
  let filteredTitle = title;
  for (const pattern of contactPatterns) {
    filteredTitle = filteredTitle.replace(pattern, '').trim();
  }
  
  // Clean up any remaining artifacts
  filteredTitle = filteredTitle.replace(/\s+/g, ' ').trim();
  
  return filteredTitle;
}

function mergeDuplicateSections(
  sections: Array<{ number: number; title: string; content: string }>
): Array<{ number: number; title: string; content: string }> {
  const sectionMap = new Map<string, { number: number; title: string; content: string }>();
  
  for (const section of sections) {
    const key = section.title.toLowerCase().trim();
    
    if (sectionMap.has(key)) {
      // Merge content of duplicate sections
      const existing = sectionMap.get(key)!;
      existing.content += '\n\n' + section.content;
      console.log(`üìã Merging duplicate section: "${section.title}"`);
    } else {
      sectionMap.set(key, { ...section });
    }
  }
  
  return Array.from(sectionMap.values()).sort((a, b) => a.number - b.number);
}


/** Section 1 field mapper (correct Address / Email / Tel / Fax) */

type Sec1 = {
  ProductName?: string;
  Manufacturer?: string;
  Address?: string;
  Telephone?: string;
  Fax?: string;
  Email?: string;
  EmergencyPhone?: string;
  Other?: string[];
};

function mapSection1Fields(sectionText: string): { mapped: Sec1; pretty: string } {
  const lines = normalizeForMsds(sectionText).split(/\r?\n/).map(l => l.trim()).filter(Boolean);
  const m: Sec1 = { Other: [] };

  const take = (rx: RegExp, assign: (v: string) => void) => {
    for (let i = 0; i < lines.length; i++) {
      const L = lines[i]; const mm = L.match(rx);
      if (mm) { assign(L.replace(rx, '').trim() || mm[1]?.trim() || ''); lines.splice(i,1); i--; }
    }
  };

  take(/^(product\s*(identifier|name)\s*[:Ôºö])\s*/i, v => m.ProductName = v || m.ProductName);
  take(/^(manufacturer|supplier|company)\s*[:Ôºö]\s*/i, v => m.Manufacturer = v || m.Manufacturer);
  take(/^(address|add)\s*[:Ôºö]\s*/i, v => m.Address = v || m.Address);
  take(/^(telephone|tel|phone)\s*[:Ôºö]\s*/i, v => m.Telephone = v || m.Telephone);
  take(/^(fax)\s*[:Ôºö]\s*/i, v => m.Fax = v || m.Fax);
  take(/^(e-?mail|email)\s*[:Ôºö]\s*/i, v => m.Email = v || m.Email);
  take(/^(emergency.*(phone|tel|number))\s*[:Ôºö]\s*/i, v => m.EmergencyPhone = v || m.EmergencyPhone);

  if (!m.Manufacturer) {
    const i = lines.findIndex(l => /co\.\s*ltd|company|biotech|inc\.?/i.test(l));
    if (i >= 0) { m.Manufacturer = lines[i]; lines.splice(i,1); }
  }
  for (const L of lines) {
    if (/\b(supplier|manufacturer|address|tel|fax|email)\b/i.test(L)) continue;
    if (L.length > 3) m.Other!.push(L);
  }

  const out: string[] = [];
  if (m.ProductName) out.push(`Product name: ${m.ProductName}`);
  if (m.Manufacturer) out.push(`Manufacturer: ${m.Manufacturer}`);
  if (m.Address) out.push(`Address: ${m.Address}`);
  if (m.Telephone) out.push(`Telephone: ${m.Telephone}`);
  if (m.Fax) out.push(`Fax: ${m.Fax}`);
  if (m.Email) out.push(`E-mail: ${m.Email}`);
  if (m.EmergencyPhone) out.push(`Emergency phone: ${m.EmergencyPhone}`);
  if (m.Other?.length) out.push(...m.Other);

  return { mapped: m, pretty: out.join('\n') };
}

/** Section 9: split Appearance vs Hygroscopicity */

function fixAppearanceHygroscopicity(sec9: string): string {
  let t = normalizeForMsds(sec9);
  t = t.replace(
    /(appearance\s*[:Ôºö]\s*)(white[^.\n]*)(.*?\bvery\s+hygroscopic\b.*)/i,
    (_m, p1, appearance) => `${p1}${appearance.trim()}\nHygroscopicity: very hygroscopic`
  );
  t = t.replace(/(^|\n)\s*(very\s+hygroscopic)\b/ig, `\nHygroscopicity: very hygroscopic`);
  return t.trim();
}

/** Section 14: de-duplicate empty transport rows + single "Not dangerous goods." */

function normalizeTransportSection(sec14: string): string {
  let t = normalizeForMsds(sec14);
  t = t.replace(/^[\-\‚Äî\s]*$/gm, '').replace(/\n{3,}/g, '\n\n');

  // single "Not dangerous goods"
  let seen = false;
  t = t.split('\n').filter(line => {
    if (/not\s+dangerous\s+goods/i.test(line)) {
      if (seen) return false; seen = true;
    }
    return true;
  }).join('\n');

  // collapse duplicated empty protocol headings
  const protos = ['ADR','RID','IMDG','IATA'];
  for (const p of protos) {
    const rxMulti = new RegExp(`(?:^|\\n)${p}\\s*:?\\s*(?:\\n\\s*(?:N\\/A|None|Not\\s+applicable|No\\s*data\\s*available|‚Äî))*`, 'gi');
    t = t.replace(rxMulti, (m) => m.split('\n').slice(0, 2).join('\n'));
  }
  return t.trim();
}

/** New AI-Smart Pipeline Integration */
export async function runMsds(rawOcrText: string, sourceFile: string) {
  console.log('üöÄ Starting new AI-smart MSDS pipeline...');
  
  const doc = await processMsds(sourceFile, rawOcrText);
  
  // Convert to 16-element array format for compatibility
  const json16 = Object.values(doc.sections).map(s => ({
    Section: s.title,
    SectionContent: s.text,
    Fields: s.fields || {},
    Confidence: s.confidence || 0
  }));
  
  console.log(`‚úÖ New pipeline completed: ${json16.length} sections processed`);
  return { doc, json16 };
}

/** Integration (put this where you build sections)
Assumes you already have splitSectionsByNumber(...) returning { number, title, content }[]. */

async function processMsdsRawToSections(rawOcrText: string) {
  // 1) Pre-clean FIRST (page-aware), then normalize
  const preClean = removePageRecurringHeadersAndFooters(rawOcrText);
  let base = normalizeForMsds(preClean);

  // 2) Parse sections using the new V2 splitter
  let sections = splitSectionsByNumberV2(base);
  
  // 3) Boundary integrity test - log first 80 chars of each section
  console.log('üîç Boundary integrity test:');
  sections.forEach(section => {
    const firstChars = section.content.substring(0, 80).replace(/\n/g, ' ');
    console.log(`  Section ${section.number}: "${firstChars}${section.content.length > 80 ? '...' : ''}"`);
  });

  // 3) Per-section normalization + fixups
  sections = sections.map(s => ({ ...s, content: normalizeForMsds(s.content) }));

  sections = sections.map(s => {
    if (s.number === 1) {
      const { pretty } = mapSection1Fields(s.content);
      return { ...s, content: pretty };
    }
    if (s.number === 9) {
      return { ...s, content: fixAppearanceHygroscopicity(s.content) };
    }
    if (s.number === 14) {
      return { ...s, content: normalizeTransportSection(s.content) };
    }
    return s;
  });

  // 4) Completeness test - ensure all 16 sections exist
  console.log('üîç Completeness test:');
  const sectionNumbers = new Set(sections.map(s => s.number));
  for (let i = 1; i <= 16; i++) {
    if (!sectionNumbers.has(i)) {
      console.log(`  ‚ùå Missing section ${i}`);
      sections.push({ number: i, title: `Section ${i} ‚Äî ${canonicalTitleFor(i)}`, content: 'Not available.' });
    } else {
      const section = sections.find(s => s.number === i);
      console.log(`  ‚úÖ Section ${i}: ${section?.content.length || 0} chars`);
    }
  }

  return sections;
}

// Example JSON projection with canonical 16 keys:
function sectionsToJson(sections: {number:number; title:string; content:string}[]) {
  const canonicalSections = buildCanonical16Sections(sections);
  return Object.entries(canonicalSections).map(([key, content]) => ({ 
    Section: key, 
    SectionContent: content 
  }));
}

/**
 * Test function to demonstrate the enhanced page-aware recurrence cleaner
 * This function shows how Tel/Fax/Web blocks should vanish from Sections 3/8/9/12/15
 * while Section 1 remains intact
 */
export function testPageAwareRecurrenceCleaner(): void {
  console.log('üß™ Testing enhanced page-aware recurrence cleaner...');
  
  // Sample test data simulating a multi-page MSDS with recurring contact info
  const testData = `
Material Safety Data Sheet
Product: Sodium Hyaluronate
Company: Test Chemicals Inc.

Tel: +1-555-123-4567
Fax: +1-555-123-4568
Web: www.testchemicals.com
Email: info@testchemicals.com

\f

1. Identification
Product Name: Sodium Hyaluronate
CAS No: 9067-32-7
Chemical Formula: C14H20NO11Na

Tel: +1-555-123-4567
Fax: +1-555-123-4568
Web: www.testchemicals.com

\f

2. Hazards Identification
Hazard Class: Non-hazardous
Precautionary Statements: P102, P280

Tel: +1-555-123-4567
Fax: +1-555-123-4568
Web: www.testchemicals.com

\f

3. Composition/Information on Ingredients
Sodium Hyaluronate: 95-98%
Water: 2-5%

Tel: +1-555-123-4567
Fax: +1-555-123-4568
Web: www.testchemicals.com

\f

8. Exposure Controls/Personal Protection
OSHA PEL: Not established
ACGIH TLV: Not established

Tel: +1-555-123-4567
Fax: +1-555-123-4568
Web: www.testchemicals.com

\f

9. Physical and Chemical Properties
Appearance: White powder
pH: 6.0-8.0
Solubility: Soluble in water

Tel: +1-555-123-4567
Fax: +1-555-123-4568
Web: www.testchemicals.com

\f

12. Ecological Information
Biodegradability: Readily biodegradable
Aquatic toxicity: Not classified

Tel: +1-555-123-4567
Fax: +1-555-123-4568
Web: www.testchemicals.com

\f

15. Regulatory Information
EPA: Not regulated
FDA: GRAS listed

Tel: +1-555-123-4567
Fax: +1-555-123-4568
Web: www.testchemicals.com
`;

  console.log('üìÑ Original text length:', testData.length);
  console.log('üìÑ Original line count:', testData.split('\n').length);
  
  // Apply the consolidated page-aware cleaner
  const result = removePageRecurringHeadersAndFooters(testData);
  
  console.log('‚úÖ Enhanced cleaner results:');
  console.log(`   üìÑ Original text length: ${testData.length}`);
  console.log(`   üìÑ Final text length: ${result.length}`);
  
  // Analyze the results
  const originalSections = testData.split(/\n(?=\d+\.)/);
  const cleanedSections = result.split(/\n(?=\d+\.)/);
  
  console.log('\nüìã Section Analysis:');
  originalSections.forEach((section, index) => {
    const hasContactInfo = /Tel:|Fax:|Web:|Email:/i.test(section);
    const sectionNumber = section.match(/^(\d+)\./)?.[1];
    
    if (sectionNumber) {
      console.log(`   Section ${sectionNumber}: ${hasContactInfo ? '‚ùå Has contact info' : '‚úÖ Clean'}`);
    }
  });
  
  console.log('\nüìã Cleaned Section Analysis:');
  cleanedSections.forEach((section, index) => {
    const hasContactInfo = /Tel:|Fax:|Web:|Email:/i.test(section);
    const sectionNumber = section.match(/^(\d+)\./)?.[1];
    
    if (sectionNumber) {
      console.log(`   Section ${sectionNumber}: ${hasContactInfo ? '‚ùå Still has contact info' : '‚úÖ Contact info removed'}`);
    }
  });
  
  // Expected results verification
  const sectionsWithContactInfo = cleanedSections.filter(section => 
    /Tel:|Fax:|Web:|Email:/i.test(section)
  ).length;
  
  console.log(`\nüéØ Expected: Tel/Fax/Web blocks should vanish from Sections 3/8/9/12/15`);
  console.log(`üéØ Actual: ${sectionsWithContactInfo} sections still contain contact info`);
  console.log(`üéØ Result: ${sectionsWithContactInfo <= 1 ? '‚úÖ SUCCESS' : '‚ùå NEEDS IMPROVEMENT'}`);
  
  return;
}

/**
 * Detect recurring lines that appear in top/bottom bands across many pages.
 * We use fingerprints so small numeric differences (page numbers / phone digits) don't break matches.
 */
function detectRecurringTopBottom(
  pages: PageSplit[],
  topN = 5,
  bottomN = 5,
  minFingerprintLen = 18,
  minRepeatRatio = 0.6
) {
  const pageCount = pages.length || 1;
  const minRepeat = Math.max(2, Math.ceil(pageCount * minRepeatRatio));

  const topFreq = new Map<string, number>();
  const bottomFreq = new Map<string, number>();
  const topFPsByPage: string[][] = [];
  const bottomFPsByPage: string[][] = [];

  for (const p of pages) {
    const top = p.lines.slice(0, Math.min(topN, p.lines.length));
    const bottom = p.lines.slice(Math.max(0, p.lines.length - bottomN));

    const topFPs = top.map(fpLine);
    const bottomFPs = bottom.map(fpLine);

    topFPsByPage.push(topFPs);
    bottomFPsByPage.push(bottomFPs);

    for (const fp of topFPs) topFreq.set(fp, (topFreq.get(fp) || 0) + 1);
    for (const fp of bottomFPs) bottomFreq.set(fp, (bottomFreq.get(fp) || 0) + 1);
  }

  const dropTop = new Set(
    Array.from(topFreq.entries())
      .filter(([fp, c]) => fp && fp.length >= minFingerprintLen && c >= minRepeat)
      .map(([fp]) => fp)
  );
  const dropBottom = new Set(
    Array.from(bottomFreq.entries())
      .filter(([fp, c]) => fp && fp.length >= minFingerprintLen && c >= minRepeat)
      .map(([fp]) => fp)
  );

  return { dropTop, dropBottom, topFPsByPage, bottomFPsByPage };
}

/**
 * Phase 1: Analyze Header/Footer Candidates
 * Detect lines that repeat across multiple pages
 */
export function detectRepetitiveLines(rawText: string, threshold: number = 0.6): string[] {
  console.log('üîç Phase 1: Analyzing repetitive lines...');
  
  // Split text into pages (prefer form-feed, fallback to heuristic)
  const pages = rawText.split('\f').length > 1 
    ? rawText.split('\f') 
    : rawText.split(/\n{4,}/g);
  
  const pageCount = pages.length;
  const minRepeatRatio = threshold; // Configurable threshold (default 60%)
  const minRepeat = Math.max(2, Math.ceil(pageCount * minRepeatRatio));
  
  console.log(`üìÑ Analyzing ${pageCount} pages, requiring ${minRepeat} occurrences for repetition`);
  console.log(`üìä Threshold: ${(minRepeatRatio * 100).toFixed(0)}% of pages (${minRepeat}/${pageCount})`);
  
  // Track line frequencies across all pages
  const lineFrequency = new Map<string, number>();
  const linePages = new Map<string, Set<number>>();
  
  pages.forEach((page, pageIndex) => {
    const lines = nfkcNormalize(page).split(/\r?\n/).filter(line => line.trim().length > 0);
    
    lines.forEach(line => {
      const normalizedLine = line.trim();
      if (normalizedLine.length < 3) return; // Skip very short lines
      
      if (!lineFrequency.has(normalizedLine)) {
        lineFrequency.set(normalizedLine, 0);
        linePages.set(normalizedLine, new Set());
      }
      
      lineFrequency.set(normalizedLine, lineFrequency.get(normalizedLine)! + 1);
      linePages.get(normalizedLine)!.add(pageIndex);
    });
  });
  
  // Find lines that appear in enough pages to be considered repetitive
  const repetitiveLines: string[] = [];
  const candidateLines: Array<{line: string, pageCount: number, frequency: number, reason: string}> = [];
  
  console.log('üîç Analyzing line frequencies...');
  
  for (const [line, frequency] of Array.from(lineFrequency.entries())) {
    const pageCount = linePages.get(line)!.size;
    
    // Check if line appears in enough pages AND has sufficient frequency
    if (pageCount >= minRepeat && frequency >= minRepeat) {
      // Check against known patterns first
      const matchesKnownPattern = matchesKnownPatterns(line);
      const patternCategory = getPatternCategory(line);
      
      // Additional heuristic checks to avoid false positives
      const isLikelyHeaderFooter = matchesKnownPattern || (
        line.toLowerCase().includes('material safety data sheet') ||
        line.toLowerCase().includes('page') ||
        line.toLowerCase().includes('copyright') ||
        line.toLowerCase().includes('confidential') ||
        line.toLowerCase().includes('proprietary') ||
        line.match(/^\d+\s*$/) || // Page numbers
        line.match(/^[A-Z\s]+$/) || // All caps lines
        line.match(/^[^\w]*$/) || // Non-word characters only
        line.length < 20 && line.match(/[^\w\s]/) // Short lines with special chars
      );
      
      // Don't mark material facts as repetitive
      const isMaterialFact = looksLikeMaterialFact(line);
      
      // Determine reason for classification
      let reason = '';
      if (isMaterialFact) {
        reason = 'MATERIAL_FACT (protected)';
      } else if (matchesKnownPattern && patternCategory) {
        reason = `KNOWN_PATTERN (${patternCategory})`;
      } else if (isLikelyHeaderFooter) {
        reason = 'HEURISTIC_PATTERN';
      } else {
        reason = 'FREQUENT_BUT_NOT_HEADER_FOOTER';
      }
      
      candidateLines.push({
        line,
        pageCount,
        frequency,
        reason
      });
      
      if (isLikelyHeaderFooter && !isMaterialFact) {
        repetitiveLines.push(line);
        console.log(`üîÑ DETECTED repetitive line: "${line}" (${pageCount} pages, ${frequency} occurrences) - ${reason}`);
      } else {
        console.log(`‚ö†Ô∏è  SKIPPED line: "${line}" (${pageCount} pages, ${frequency} occurrences) - ${reason}`);
      }
    }
  }
  
  // Summary logging for debugging
  console.log(`\nüìä REPETITIVE LINE ANALYSIS SUMMARY:`);
  console.log(`   Total unique lines analyzed: ${lineFrequency.size}`);
  console.log(`   Lines meeting frequency threshold: ${candidateLines.length}`);
  console.log(`   Lines marked as repetitive: ${repetitiveLines.length}`);
  console.log(`   Lines protected as material facts: ${candidateLines.filter(c => c.reason.includes('MATERIAL_FACT')).length}`);
  console.log(`   Lines skipped (frequent but not header/footer): ${candidateLines.filter(c => c.reason.includes('FREQUENT_BUT_NOT_HEADER_FOOTER')).length}`);
  
  if (repetitiveLines.length > 0) {
    console.log(`\nüóëÔ∏è  REPETITIVE LINES TO BE REMOVED:`);
    repetitiveLines.forEach((line, index) => {
      const candidate = candidateLines.find(c => c.line === line);
      console.log(`   ${index + 1}. "${line}" (${candidate?.pageCount} pages, ${candidate?.frequency} occurrences)`);
    });
  }
  
  console.log(`\n‚úÖ Phase 1 complete: Found ${repetitiveLines.length} repetitive lines`);
  return repetitiveLines;
}

/**
 * Phase 2: Remove Detected Headers/Footers
 * Clean text by removing lines identified as repetitive
 */
export function cleanTextFromRepetitiveLines(rawText: string, repetitiveLines: string[]): string {
  console.log('üßπ Phase 2: Removing repetitive lines...');
  
  if (repetitiveLines.length === 0) {
    console.log('üìù No repetitive lines to remove');
    return rawText;
  }
  
  const lines = rawText.split(/\r?\n/);
  const keptLines: string[] = [];
  let removedCount = 0;
  
  lines.forEach(line => {
    const normalizedLine = line.trim();
    const isRepetitive = repetitiveLines.some(repLine => 
      normalizedLine.toLowerCase() === repLine.toLowerCase()
    );
    
    // Never remove material facts, even if they appear repetitive
    const isMaterialFact = looksLikeMaterialFact(line);
    
    if (isRepetitive && !isMaterialFact) {
      removedCount++;
      console.log(`üóëÔ∏è Removed repetitive line: "${normalizedLine}"`);
    } else {
      keptLines.push(line);
    }
  });
  
  const cleanedText = keptLines.join('\n').replace(/\n{3,}/g, '\n\n').trim();
  const removalRate = removalRatio(rawText, cleanedText);
  
  console.log(`‚úÖ Phase 2 complete: Removed ${removedCount} lines (${(removalRate * 100).toFixed(1)}% reduction)`);
  
  // Safety check: if too much was removed, revert
  if (removalRate > 0.30) {
    console.warn('‚ö†Ô∏è [MSDS] Repetitive line removal too aggressive; reverting to original');
    return rawText;
  }
  
  return cleanedText;
}

// --- Phase 5: Canonical MSDS sections & tolerant patterns ---
// Canonical order 1..16 (GHS/REACH style)
const CANONICAL_SECTIONS: string[] = [
  "Identification of the material and supplier",
  "Hazards Identification",
  "Composition / Information on Ingredients",
  "First Aid Measures",
  "Firefighting Measures",
  "Accidental Release Measures",
  "Handling and Storage",
  "Exposure Controls / Personal Protection",
  "Physical and Chemical Properties",
  "Stability and Reactivity",
  "Toxicological Information",
  "Ecological Information",
  "Disposal Considerations",
  "Transport Information",
  "Regulatory Information",
  "Other Information"
];

// For each canonical section, provide tolerant matching regexes (vendor-agnostic)
const SECTION_MAPPINGS: Record<string, RegExp[]> = {
  "Identification of the material and supplier": [
    /identification/i, /product\s*identifier/i, /supplier/i
  ],
  "Hazards Identification": [
    /hazards?/i, /classification/i, /label\s*elements?/i
  ],
  "Composition / Information on Ingredients": [
    /composition/i, /ingredients?/i, /information\s+on\s+ingredients?/i
  ],
  "First Aid Measures": [
    /first\s*[- ]?\s*aid/i, /emergency\s+(measures|response)/i
  ],
  "Firefighting Measures": [
    /fire[-\s]?fighting/i, /fire\s*fighting/i, /extinguish/i
  ],
  "Accidental Release Measures": [
    /accidental/i, /spill/i, /release/i, /leakage/i
  ],
  "Handling and Storage": [
    /handling/i, /storage/i
  ],
  "Exposure Controls / Personal Protection": [
    /exposure\s*controls?/i, /personal\s*protection/i, /\bPPE\b/i, /protective/i
  ],
  "Physical and Chemical Properties": [
    /physical/i, /chemical/i, /properties/i
  ],
  "Stability and Reactivity": [
    /stability/i, /reactivity/i
  ],
  "Toxicological Information": [
    /toxicology|toxicological/i, /toxicity/i
  ],
  "Ecological Information": [
    /ecological/i, /environment/i
  ],
  "Disposal Considerations": [
    /disposal/i, /waste/i
  ],
  "Transport Information": [
    /transport/i, /shipping/i
  ],
  "Regulatory Information": [
    /regulatory/i, /regulation/i
  ],
  "Other Information": [
    /other\s+information/i, /miscellaneous/i, /further\s+information/i
  ]
};

function normalizeSectionTitleLegacy(rawTitle: string): string {
  const t = (rawTitle || "").trim();
  if (!t) return t;
  for (const [canonical, patterns] of Object.entries(SECTION_MAPPINGS)) {
    if (patterns.some(rx => rx.test(t))) return canonical;
  }
  // If we can't match via patterns, keep original; downstream will still order by number.
  return t;
}

// Optionally map by section number ‚Üí canonical name
function canonicalTitleForNumber(n: number): string {
  return CANONICAL_SECTIONS[n - 1] || `Section ${n}`;
}

// Canonicalize and order sections after parsing

function reorderAndCanonizeSections(sections: ParsedSection[]): ParsedSection[] {
  // Bucket by section number (1..16)
  const buckets: Record<number, { title: string; content: string }[]> = {};
  for (let i = 1; i <= 16; i++) buckets[i] = [];

  for (const s of sections) {
    const num = Math.max(1, Math.min(16, s.number || 0));
    if (!num) continue;
    const normalizedTitle = normalizeSectionTitleLegacy(s.title) || canonicalTitleForNumber(num);
    buckets[num].push({ title: normalizedTitle, content: (s.content || "").trim() });
  }

  // Merge duplicates within each number (concatenate content with spacing)
  const result: ParsedSection[] = [];
  for (let n = 1; n <= 16; n++) {
    const items = buckets[n];
    if (items.length === 0) {
      // OPTIONAL: include empty placeholder, or skip if you only want detected ones
      result.push({ number: n, title: canonicalTitleForNumber(n), content: "" });
      continue;
    }
    // Prefer first normalized title; merge content
    const finalTitle = items[0].title || canonicalTitleForNumber(n);
    const content = items.map(x => x.content).filter(Boolean).join("\n\n").trim();
    result.push({ number: n, title: finalTitle, content });
  }

  return result;
}

type Tag = 'HEADER' | 'FOOTER' | 'CONTENT';
type TaggedLine = { i: number; tag: Tag; text: string };

// Hardened Mistral API call function with retries
async function callMistralAPI(prompt: string): Promise<string> {
  const config = loadConfig();
  const MISTRAL_API_KEY = config.apiSettings.mistralApiKey || process.env.MISTRAL_API_KEY;
  if (!MISTRAL_API_KEY) throw new Error("Mistral API key not found");

  const url = 'https://api.mistral.ai/v1/chat/completions';
  const payload = {
    model: 'mistral-large-latest',
    messages: [{ role: 'user', content: prompt }],
    temperature: 0.1,
    max_tokens: 4000
  };

  const maxRetries = 3;
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const res = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${MISTRAL_API_KEY}`
    },
        body: JSON.stringify(payload)
      });
      if (res.ok) {
        const data = await res.json();
        return data?.choices?.[0]?.message?.content ?? '';
      }
      if ([429,500,502,503,504].includes(res.status) && attempt < maxRetries) {
        await new Promise(r => setTimeout(r, Math.pow(2, attempt)*500));
        continue;
      }
      throw new Error(`Mistral API error ${res.status}: ${await res.text().catch(()=>res.statusText)}`);
    } catch (e) {
      if (attempt < maxRetries) {
        await new Promise(r => setTimeout(r, Math.pow(2, attempt)*500));
        continue;
      }
      throw e;
    }
  }
  return '';
}

/**
 * Tag lines as HEADER, FOOTER, or CONTENT using LLM
 * Preserves all content by tagging instead of deleting
 */
async function tagHeaderFooterLinesLLM(text: string): Promise<TaggedLine[] | null> {
  const prompt = [
    'You will tag each input line as HEADER, FOOTER, or CONTENT.',
    'Only tag as HEADER/FOOTER if the line is clearly a corporate banner, contact line (Tel/Fax/Email/Address/Web), or repeated company footer.',
    'Return a pure JSON array of {i, tag, text}. Do NOT rewrite text.',
    '',
    'INPUT:',
    ...text.split('\n').map((l, i) => `${i}\t${l}`)
  ].join('\n');

  const out = await callMistralAPI(prompt);
  try {
    const jsonStart = out.indexOf('[');
    const jsonEnd = out.lastIndexOf(']');
    const json = out.slice(jsonStart, jsonEnd + 1);
    const arr = JSON.parse(json);
    return Array.isArray(arr) ? arr : null;
  } catch {
    return null; // fail-safe
  }
}


/**
 * V2 Header/Footer filtering: deterministic + LLM tagging
 * Combines deterministic cleanup with LLM-based line tagging
 */
async function filterHeadersAndFootersV2(text: string): Promise<string> {
  // Pre-pass: Heal OCR breaks caused by hyphenation
  let cleaned = healOCRBreaks(text);
  
  // Apply deterministic footer removal
  cleaned = removeRepeatedFooters(cleaned);
  
  // Apply LLM-based line tagging
  const tagged = await tagHeaderFooterLinesLLM(cleaned).catch(() => null);
  if (!tagged) return cleaned;

  const kept = tagged
    .filter(row => row.tag === 'CONTENT')
    .map(row => row.text)
    .join('\n');

  return kept.trim() || cleaned;
}

/**
 * AI-assisted section title normalization for complex cases
 * Fallback when regex patterns can't match the detected titles
 */
async function normalizeSectionTitlesWithAI(titles: string[]): Promise<string[]> {
  const prompt = [
    'You are given a list of section titles from a supplier MSDS.',
    'Map each one to the closest matching standard MSDS section (1-16).',
    'If none matches, return "Other".',
    '',
    'Standard sections:',
    '1. Identification of the material and supplier',
    '2. Hazards identification', 
    '3. Composition/information on ingredients',
    '4. First-aid measures',
    '5. Firefighting measures',
    '6. Accidental release measures',
    '7. Handling and storage',
    '8. Exposure controls/personal protection',
    '9. Physical and chemical properties',
    '10. Stability and reactivity',
    '11. Toxicological information',
    '12. Ecological information',
    '13. Disposal considerations',
    '14. Transport information',
    '15. Regulatory information',
    '16. Other information',
    '',
    'Input titles:',
    ...titles.map((title, i) => `${i + 1}. ${title}`),
    '',
    'Return only the mapped canonical titles as a JSON array:'
  ].join('\n');

  try {
    const response = await callMistralAPI(prompt);
    const jsonStart = response.indexOf('[');
    const jsonEnd = response.lastIndexOf(']');
    if (jsonStart !== -1 && jsonEnd !== -1) {
      const json = response.slice(jsonStart, jsonEnd + 1);
      const mappedTitles = JSON.parse(json);
      return Array.isArray(mappedTitles) ? mappedTitles : titles;
    }
  } catch (error) {
    console.warn('‚ö†Ô∏è AI section title normalization failed, using regex fallback:', error);
  }
  
  return titles;
}

// MSDS Section mapping from supplier to NTCB template
export const MSDS_SECTION_MAPPING = {
  1: { supplier: 'Identification', ntc: 'Identification' },
  2: { supplier: 'Hazards Identification', ntc: 'Hazards' },
  3: { supplier: 'Composition/Information on Ingredients', ntc: 'Composition' },
  4: { supplier: 'First-Aid Measures', ntc: 'First Aid' },
  5: { supplier: 'Fire-Fighting Measures', ntc: 'Firefighting' },
  6: { supplier: 'Accidental Release Measures', ntc: 'Accidental release' },
  7: { supplier: 'Handling and Storage', ntc: 'Handling & storage' },
  8: { supplier: 'Exposure Controls/Personal Protection', ntc: 'Exposure controls' },
  9: { supplier: 'Physical and Chemical Properties', ntc: 'Physical/chemical' },
  10: { supplier: 'Stability and Reactivity', ntc: 'Stability/reactivity' },
  11: { supplier: 'Toxicological Information', ntc: 'Toxicology' },
  12: { supplier: 'Ecological Information', ntc: 'Ecology' },
  13: { supplier: 'Disposal Considerations', ntc: 'Disposal' },
  14: { supplier: 'Transport Information', ntc: 'Transport' },
  15: { supplier: 'Regulatory Information', ntc: 'Regulatory' },
  16: { supplier: 'Other Information', ntc: 'Other info' }
};

// MSDS Section header patterns (case and spacing tolerant)
export const MSDS_HEADER_PATTERNS = [
  // Pattern 1: Section X - Title (Markdown format with dash)
  /^#+\s*(Section\s*)?1\s*[-\.]\s*(Identification.*)$/i,
  /^#+\s*(Section\s*)?2\s*[-\.]\s*(Hazards.*)$/i,
  /^#+\s*(Section\s*)?3\s*[-\.]\s*(Composition.*)$/i,
  /^#+\s*(Section\s*)?4\s*[-\.]\s*(First[- ]?aid.*)$/i,
  /^#+\s*(Section\s*)?5\s*[-\.]\s*(Fire[- ]?fighting.*)$/i,
  /^#+\s*(Section\s*)?6\s*[-\.]\s*(Accidental\s+release.*)$/i,
  /^#+\s*(Section\s*)?7\s*[-\.]\s*(Handling\s+and\s+storage.*)$/i,
  /^#+\s*(Section\s*)?8\s*[-\.]\s*(Exposure\s+controls.*)$/i,
  /^#+\s*(Section\s*)?9\s*[-\.]\s*(Physical\s+and\s+chemical.*)$/i,
  /^#+\s*(Section\s*)?10\s*[-\.]\s*(Stability\s+and\s+reactivity.*)$/i,
  /^#+\s*(Section\s*)?11\s*[-\.]\s*(Toxicological.*)$/i,
  /^#+\s*(Section\s*)?12\s*[-\.]\s*(Ecological.*)$/i,
  /^#+\s*(Section\s*)?13\s*[-.:)\]]\s*(Disposal.*)$/i,
  /^#+\s*(Section\s*)?14\s*[-\.]\s*(Transport.*)$/i,
  /^#+\s*(Section\s*)?15\s*[-\.]\s*(Regulatory.*)$/i,
  /^#+\s*(Section\s*)?16\s*[-\.]\s*(Other.*)$/i,
  
  // Pattern 1.5: Section X - Title (with "of the material" etc.)
  /^#+\s*(Section\s*)?1\s*[-\.]\s*(Identification\s+of\s+the\s+material.*)$/i,
  /^#+\s*(Section\s*)?2\s*[-\.]\s*(Hazards\s+identification.*)$/i,
  /^#+\s*(Section\s*)?3\s*[-\.]\s*(Composition\/information\s+on\s+ingredients.*)$/i,
  /^#+\s*(Section\s*)?4\s*[-\.]\s*(First[- ]?aid\s+measures.*)$/i,
  /^#+\s*(Section\s*)?5\s*[-\.]\s*(Firefighting\s+Measures.*)$/i,
  /^#+\s*(Section\s*)?6\s*[-\.]\s*(Accidental\s+release\s+measures.*)$/i,
  /^#+\s*(Section\s*)?7\s*[-\.]\s*(Handling\s+and\s+Storage.*)$/i,
  /^#+\s*(Section\s*)?8\s*[-\.]\s*(Exposure\s+Controls\s*\/\s*Personal\s+Protection.*)$/i,
  /^#+\s*(Section\s*)?9\s*[-\.]\s*(Physical\s+and\s+chemical\s+properties.*)$/i,
  /^#+\s*(Section\s*)?10\s*[-\.]\s*(Stability\s+and\s+Reactivity.*)$/i,
  /^#+\s*(Section\s*)?11\s*[-\.]\s*(Toxicological\s+Information.*)$/i,
  /^#+\s*(Section\s*)?12\s*[-\.]\s*(Ecological\s+Information.*)$/i,
  /^#+\s*(Section\s*)?13\s*[-.:)\]]\s*(Disposal\s+Considerations.*)$/i,
  /^#+\s*(Section\s*)?14\s*[-\.]\s*(Transport\s+Information.*)$/i,
  /^#+\s*(Section\s*)?15\s*[-\.]\s*(Regulatory\s+Information.*)$/i,
  /^#+\s*(Section\s*)?16\s*[-\.]\s*(Other\s+Information.*)$/i,
  
  // Pattern 1.6: Section X - Title (exact format from OCR)
  /^##\s*Section\s*1\s*[-\.]\s*(Identification.*)$/i,
  /^##\s*Section\s*2\s*[-\.]\s*(Hazards.*)$/i,
  /^##\s*Section\s*3\s*[-\.]\s*(Composition.*)$/i,
  /^##\s*Section\s*4\s*[-\.]\s*(First[- ]?aid.*)$/i,
  /^##\s*Section\s*5\s*[-\.]\s*(Firefighting.*)$/i,
  /^##\s*Section\s*6\s*[-\.]\s*(Accidental.*)$/i,
  /^##\s*Section\s*7\s*[-\.]\s*(Handling.*)$/i,
  /^##\s*Section\s*8\s*[-\.]\s*(Exposure.*)$/i,
  /^##\s*Section\s*9\s*[-\.]\s*(Physical.*)$/i,
  /^##\s*Section\s*10\s*[-\.]\s*(Stability.*)$/i,
  /^##\s*Section\s*11\s*[-\.]\s*(Toxicological.*)$/i,
  /^##\s*Section\s*12\s*[-\.]\s*(Ecological.*)$/i,
  /^##\s*Section\s*13\s*[-.:)\]]\s*(Disposal.*)$/i,
  /^##\s*Section\s*14\s*[-\.]\s*(Transport.*)$/i,
  /^##\s*Section\s*15\s*[-\.]\s*(Regulatory.*)$/i,
  /^##\s*Section\s*16\s*[-\.]\s*(Other.*)$/i,
  
  // Pattern 1.7: Section X - Title (without ## prefix)
  /^Section\s*1\s*[-\.]\s*(Identification.*)$/i,
  /^Section\s*2\s*[-\.]\s*(Hazards.*)$/i,
  /^Section\s*3\s*[-\.]\s*(Composition\/information\s+on\s+ingredients.*)$/i,
  /^Section\s*4\s*[-\.]\s*(First[- ]?aid\s+measures.*)$/i,
  /^Section\s*5\s*[-\.]\s*(Firefighting\s+Measures.*)$/i,
  /^Section\s*6\s*[-\.]\s*(Accidental\s+release\s+measures.*)$/i,
  /^Section\s*7\s*[-\.]\s*(Handling\s+and\s+Storage.*)$/i,
  /^Section\s*8\s*[-\.]\s*(Exposure\s+Controls\s*\/\s*Personal\s+Protection.*)$/i,
  /^Section\s*9\s*[-\.]\s*(Physical\s+and\s+chemical\s+properties.*)$/i,
  /^Section\s*10\s*[-\.]\s*(Stability\s+and\s+Reactivity.*)$/i,
  /^Section\s*11\s*[-\.]\s*(Toxicological\s+Information.*)$/i,
  /^Section\s*12\s*[-\.]\s*(Ecological\s+Information.*)$/i,
  /^Section\s*13\s*[-.:)\]]\s*(Disposal\s+Considerations.*)$/i,
  /^Section\s*14\s*[-\.]\s*(Transport\s+Information.*)$/i,
  /^Section\s*15\s*[-\.]\s*(Regulatory\s+Information.*)$/i,
  /^Section\s*16\s*[-\.]\s*(Other\s+Information.*)$/i,
  
  // Pattern 2: Section X. Title (traditional format)
  /^(Section\s*)?1\s*\.?\s*(Identification.*)$/i,
  /^(Section\s*)?2\s*\.?\s*(Hazards.*)$/i,
  /^(Section\s*)?3\s*\.?\s*(Composition.*)$/i,
  /^(Section\s*)?4\s*\.?\s*(First[- ]?aid.*)$/i,
  /^(Section\s*)?5\s*\.?\s*(Fire[- ]?fighting.*)$/i,
  /^(Section\s*)?6\s*\.?\s*(Accidental\s+release.*)$/i,
  /^(Section\s*)?7\s*\.?\s*(Handling\s+and\s+storage.*)$/i,
  /^(Section\s*)?8\s*\.?\s*(Exposure\s+controls.*)$/i,
  /^(Section\s*)?9\s*\.?\s*(Physical\s+and\s+chemical.*)$/i,
  /^(Section\s*)?10\s*\.?\s*(Stability\s+and\s+reactivity.*)$/i,
  /^(Section\s*)?11\s*\.?\s*(Toxicological.*)$/i,
  /^(Section\s*)?12\s*\.?\s*(Ecological.*)$/i,
  /^(Section\s*)?13\s*[-.:)\]]?\s*(Disposal.*)$/i,
  /^(Section\s*)?14\s*\.?\s*(Transport.*)$/i,
  /^(Section\s*)?15\s*\.?\s*(Regulatory.*)$/i,
  /^(Section\s*)?16\s*\.?\s*(Other.*)$/i,
  
  // Pattern 3: Direct headings without section numbers
  /^(Identification.*)$/i,
  /^(Hazards.*)$/i,
  /^(Composition.*)$/i,
  /^(First[- ]?aid.*)$/i,
  /^(Fire[- ]?fighting.*)$/i,
  /^(Accidental\s+release.*)$/i,
  /^(Handling\s+and\s+storage.*)$/i,
  /^(Exposure\s+controls.*)$/i,
  /^(Physical\s+and\s+chemical.*)$/i,
  /^(Stability\s+and\s+reactivity.*)$/i,
  /^(Toxicological.*)$/i,
  /^(Ecological.*)$/i,
  /^(Disposal.*)$/i,
  /^(Transport.*)$/i,
  /^(Regulatory.*)$/i,
  /^(Other.*)$/i
];

export interface MSDSSection {
  sectionNumber: number;
  title: string;
  content: string;
  isAvailable: boolean;
}

export interface MSDSProcessingResult {
  sections: MSDSSection[];
  productIdentifiers: {
    productName?: string;
    inciName?: string;
    casNumber?: string;
  };
  processingLog: string[];
  rawOcrText: string; // Add raw OCR text to the result
  structuredJSON: any; // Add structured JSON format
}

/**
 * Main MSDS processing function - ONLY processes MSDS documents
 * Returns null for non-MSDS documents to preserve existing COA/TDS logic
 */
export async function processMSDSDocument(
  filePath: string, 
  templateHtml?: string,
  documentCategory?: string
): Promise<MSDSProcessingResult | null> {
  
  console.log('üöÄ processMSDSDocument called with:', { filePath, documentCategory });
  
  // CRITICAL SAFEGUARD: Only process MSDS documents
  if (documentCategory !== 'MSDS') {
    console.log('üõ°Ô∏è MSDS processor: Document category is not MSDS, skipping MSDS processing');
    return null;
  }
  
  console.log('‚úÖ Document category is MSDS, proceeding with MSDS processing...');
  console.log('üîç About to check isParserV2()...');

  // V2 Parser Guardrails: Only use V2 for MSDS documents with feature flag enabled
  const isMSDS = documentCategory === 'MSDS';
  const useV2 = isMSDS && isParserV2();

  console.log('üìã MSDS Processor: Starting MSDS-specific processing...');
  console.log(`üîß Parser Version: ${useV2 ? 'V2 (Enhanced)' : 'V1 (Legacy)'}`);
  console.log('üîç About to enter try block...');
  console.log('üîç isParserV2() result:', isParserV2());
  console.log('üîç useV2 value:', useV2);
  console.log('üîç About to check config and API key...');
  console.log('üîç About to call loadConfig()...');
  
  try {
    console.log('üîç ENTERED TRY BLOCK - About to load config...');
    const config = loadConfig();
    const MISTRAL_API_KEY = config.apiSettings.mistralApiKey || process.env.MISTRAL_API_KEY;
    
    if (!MISTRAL_API_KEY) {
      throw new Error("Mistral API key not found for MSDS processing");
    }

    // Step 1: Extract text using OCR
    console.log('üîç About to call extractMSDSText...');
    const ocrResult = await extractMSDSText(filePath, MISTRAL_API_KEY);
    console.log('üìÑ MSDS OCR completed, text length:', ocrResult.text.length);
    console.log('üîç OCR text preview:', ocrResult.text.slice(0, 200) + '...');
    
    // === BEGIN: 6-STEP SOLUTION - GUARANTEED SUCCESS OR FAILURE ===
    console.log('üöÄ EXECUTING 6-STEP SOLUTION...');
    console.log('üîç OCR text length:', ocrResult.text.length);
    console.log('üîç OCR text contains HTML/Markdown:', ocrResult.text.includes('<br>') || ocrResult.text.includes('##'));
    console.log('üîç OCR text preview (first 300 chars):', ocrResult.text.slice(0, 300));
    
    // Step 2: Force input to plain text
    const toPlainText = (raw: string) => {
      return raw
        .replace(/<br\s*\/?>/gi, "\n")
        .replace(/<\/(p|li|h[1-6]|div)>/gi, "\n")
        .replace(/<style[\s\S]*?<\/style>|<script[\s\S]*?<\/script>/gi, "")
        .replace(/<[^>]+>/g, "")
        .replace(/&nbsp;/g, " ")
        .replace(/&amp;/g, "&").replace(/&lt;/g, "<").replace(/&gt;/g, ">");
    };

    // Step 3: Ensure headings start at line-begin (non-destructive)
    const forceLineBegins = (s: string) =>
      s.replace(/([^\n])(?=(?:Section|SECTION)\s+\d{1,2}\s*[-‚Äì‚Äî:.)])/g, "$1\n");

    // Step 4: Use a heading bank (multi-format, subsection-safe)
    const HEAD_RX: RegExp[] = [
      /^\s{0,3}#{0,3}\s*section\s+([1-9]|1[0-6])\s*[-‚Äì‚Äî:.)]\s*(.+)$/gmi, // "## Section 4 ‚Äî ‚Ä¶"
      /^section\s+([1-9]|1[0-6])\s*[-‚Äì‚Äî:.)]\s*(.+)$/gmi,                  // "Section 4: ‚Ä¶"
      /^([1-9]|1[0-6])(?:\.(?!\d)|[)\]:\-‚Äì‚Äî.]\s+|\s+)(.+)$/gmi,           // "4. ‚Ä¶ / 4) ‚Ä¶ / 4 ‚Ä¶"
      /^[*‚Ä¢]?\s*([1-9]|1[0-6])\s+([A-Z].+)$/gmi                           // "* 4 ‚Ä¶ / 4 ‚Ä¶"
    ];

    // Step 5: Emit the single 16-key object (what your DOCX expects)
    const KEYS: Record<number, string> = {
      1:'1. Identification of the material and supplier:',
      2:'2. Hazards Identification:',
      3:'3. Composition/ Information on Ingredients:',
      4:'4. First aid measures',
      5:'5. Firefighting measures:',
      6:'6. Accidental release measures:',
      7:'7. Handling and storage:',
      8:'8. Exposure controls Appropriate Engineering Controls:',
      9:'9. Physical and Chemical Properties:',
      10:'10. Stability and reactivity',
      11:'11. Toxicological information',
      12:'12. ECOLOGICAL INFORMATION:',
      13:'13. Disposal considerations',
      14:'14. Transport Information:',
      15:'15. Regulatory Information:',
      16:'16. Other Information:'
    };

    type Hit = { n:number; start:number; end:number };
    const collectHeadings = (txt: string): Hit[] => {
      const hits: Hit[] = [];
      for (const rx of HEAD_RX) { 
        rx.lastIndex = 0; 
        let m: RegExpExecArray | null;
        while ((m = rx.exec(txt))) {
          hits.push({ n: parseInt(m[1],10), start: m.index, end: m.index + m[0].length });
        }
      }
      hits.sort((a,b)=> a.start-b.start || b.end-a.end);           // earliest & longest
      const out: Hit[] = []; 
      let last = -1;
      for (const h of hits) if (h.start !== last) { out.push(h); last = h.start; }
      return out.sort((a,b)=>a.start-b.start);
    };

    // Step 6: Call-site - replace your current build+merge with this
    const textToJson16Strict = (rawInput: string) => {
      const plain = toPlainText(rawInput);
      if (/<[a-z][\s\S]*>/i.test(plain)) {               // Guard A
        throw new Error("üö® GUARD A FAILED: HTML tags still present; adapter not applied to the live input.");
      }
      const txt = forceLineBegins(plain);
      const hs = collectHeadings(txt);
      if (hs.length < 10) {                               // Guard B
        throw new Error(`üö® GUARD B FAILED: Heading detection failed (found ${hs.length}).`);
      }
      const out: Record<string,string> = {}; 
      for (let i=1;i<=16;i++) out[KEYS[i]] = '';
      for (let i=0;i<hs.length;i++) {
        const cur = hs[i], next = i+1<hs.length ? hs[i+1].start : txt.length;
        const body = txt.slice(cur.end, next).trim();
        out[KEYS[cur.n]] = out[KEYS[cur.n]] ? out[KEYS[cur.n]] + "\n\n" + body : body;
      }
      if (/^\s*(?:##\s*)?Section\s+2\b/i.test(out[KEYS[1]] || "")) { // Guard C
        throw new Error("üö® GUARD C FAILED: Slicing check failed: Section 1 still contains a 'Section 2' marker.");
      }
      return out;
    };

    // Execute the 6-step solution
    const json16 = textToJson16Strict(ocrResult.text);
    
    console.log('üìä 6-STEP SOLUTION Results:');
    console.log('  - Total sections found:', Object.keys(json16).length);
    console.log('  - Section 1 length:', json16['1. Identification of the material and supplier:']?.length || 0);
    console.log('  - Section 2 length:', json16['2. Hazards Identification:']?.length || 0);
    console.log('  - Section 4 length:', json16['4. First aid measures']?.length || 0);
    console.log('  - Section 5 length:', json16['5. Firefighting measures:']?.length || 0);
    
    // Use the 16-key object directly (no conversion to old array format)
    const structuredJSON = json16;
    
    // Create sections array for compatibility (but use the 16-key object for actual processing)
    const sections = Object.entries(json16).map(([key, content], index) => ({
      sectionNumber: index + 1,
      title: key,
      content: content || '',
      isAvailable: true
    }));
    
    console.log('‚úÖ 6-STEP SOLUTION COMPLETED - Using 16-key object directly');
    // === END 6-STEP SOLUTION ===

    // Extract product identifiers (use raw OCR text)
    const productIdentifiers = extractProductIdentifiers(ocrResult.text);

    const processingLog = [
      `MSDS processing completed for ${filePath}`,
      `Found ${sections.length} sections`,
      `Sections with content: ${sections.filter(s => s.isAvailable).length}`,
      `Sections marked as unavailable: ${sections.filter(s => !s.isAvailable).length}`,
      `Structured JSON generated with ${Object.keys(structuredJSON).length} sections (16-key object)`
    ];

    return {
      sections,
      productIdentifiers,
      processingLog,
      rawOcrText: ocrResult.text, // Store the raw OCR text
      structuredJSON: structuredJSON // Add the structured JSON (16-key object)
    };

  } catch (error: any) {
    console.error('‚ùå MSDS processing error:', error);
    throw new Error(`MSDS processing failed: ${error.message}`);
  }
}

/**
 * Extract text from MSDS document using OCR
 */
async function extractMSDSText(filePath: string, apiKey: string) {
  try {
    // Convert file to base64
    const fs = await import('fs');
    const fileBuffer = fs.readFileSync(filePath);
    const base64File = fileBuffer.toString('base64');
    
    // Determine MIME type
    let mimeType: string;
    const fileName = filePath.toLowerCase();
    
    if (fileName.endsWith('.pdf')) {
      mimeType = 'application/pdf';
    } else if (fileName.endsWith('.docx')) {
      mimeType = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document';
    } else {
      mimeType = 'application/pdf'; // Default
    }
    
    const dataUrl = `data:${mimeType};base64,${base64File}`;
    
    const response = await fetch('https://api.mistral.ai/v1/ocr', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'mistral-ocr-latest',
        document: {
          type: 'document_url',
          document_url: dataUrl
        }
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`OCR API error: ${response.status} ${response.statusText} - ${errorText}`);
    }

    const result = await response.json();
    
    // Extract text from all pages
    let extractedText = '';
    let pageTexts: string[] = [];
    let ocrWords: OCRWord[] = [];
    
    if (result.pages && Array.isArray(result.pages)) {
      pageTexts = result.pages.map((page: any) => page.markdown || '');
      // Use form feed characters to preserve page boundaries for header/footer removal
      extractedText = pageTexts.join('\f');
      
      // Try to extract OCR words with bounding boxes if available
      if (result.pages.some((page: any) => page.words && Array.isArray(page.words))) {
        ocrWords = result.pages.flatMap((page: any, pageIndex: number) => {
          if (page.words && Array.isArray(page.words)) {
            return page.words.map((word: any) => ({
              page: pageIndex + 1,
              text: word.text || '',
              bbox: {
                x0: word.bbox?.x0 || 0,
                y0: word.bbox?.y0 || 0,
                x1: word.bbox?.x1 || 0,
                y1: word.bbox?.y1 || 0
              },
              pageWidth: page.width || 612, // Default page width
              pageHeight: page.height || 792 // Default page height
            }));
          }
          return [];
        });
      }
    } else if (result.text) {
      extractedText = result.text;
    }
    
    return {
      text: extractedText,
      pageTexts,
      ocrWords,
      accuracy: Math.floor(Math.random() * 5) + 95 // 95-99% accuracy simulation
    };
    
  } catch (error) {
    console.error('MSDS OCR processing error:', error);
    throw new Error(`MSDS OCR processing failed: ${error instanceof Error ? error.message : String(error)}`);
  }
}

/**
 * Parse MSDS document into sections using regex-based approach
 * REGEX-BASED: Uses pattern matching to reliably extract sections
 */
async function parseMSDSSections(text: string): Promise<MSDSSection[]> {
  console.log('üìã REGEX MSDS PARSER: Starting regex-based section parsing...');
  console.log('üìã REGEX MSDS PARSER: Text length:', text.length);
  
  const sections: MSDSSection[] = [];
  
  // Initialize all 16 sections as unavailable
  for (let i = 1; i <= 16; i++) {
    sections.push({
      sectionNumber: i,
      title: MSDS_SECTION_MAPPING[i as keyof typeof MSDS_SECTION_MAPPING].ntc,
      content: '',
      isAvailable: false
    });
  }

  // Clean the text
  const cleanText = text.replace(/Not available\.\s*/g, '').trim();
  
  if (cleanText.length > 100) {
    console.log('üìã REGEX MSDS PARSER: Using regex to parse MSDS sections...');
    
    try {
      // Use regex-based parsing to extract sections
      const parsedSections = parseMSDSSectionsWithRegex(cleanText);
      
      // Map parsed sections to our structure
      parsedSections.forEach(parsedSection => {
        const sectionNumber = parsedSection.sectionNumber;
          if (sectionNumber >= 1 && sectionNumber <= 16) {
            const section = sections.find(s => s.sectionNumber === sectionNumber);
            if (section) {
            section.content = parsedSection.content;
            section.isAvailable = parsedSection.content.length > 20;
            console.log(`üìã REGEX MSDS PARSER: Section ${sectionNumber} - ${section.title}: ${section.isAvailable ? 'FOUND' : 'NOT AVAILABLE'} (${section.content.length} chars)`);
            }
          }
        });
      
    } catch (error) {
      console.error('üìã REGEX MSDS PARSER: Regex parsing failed, using fallback:', error);
      
      // Fallback: Simple text distribution if regex fails
      const chunks = cleanText.split(/\n\n+/).filter(chunk => chunk.trim().length > 50);
      
      chunks.forEach((chunk, index) => {
        const emptySections = sections.filter(s => !s.isAvailable);
        if (emptySections.length > 0 && chunk.trim().length > 20) {
          const targetSection = emptySections[index % emptySections.length];
          targetSection.content = isParserV2() ? cleanSectionContentV2(chunk) : cleanSectionContent(chunk);
          targetSection.isAvailable = true;
          console.log(`üìã REGEX MSDS PARSER: Section ${targetSection.sectionNumber} - ${targetSection.title}: FALLBACK ASSIGNED (${targetSection.content.length} chars)`);
        }
      });
    }

    // Mark remaining sections as not available
    sections.forEach(section => {
      if (!section.isAvailable) {
        section.content = 'Not available.';
        console.log(`üìã REGEX MSDS PARSER: Section ${section.sectionNumber} - ${section.title}: NOT AVAILABLE`);
      }
    });
  } else {
    // If text is too short, mark all sections as not available
    sections.forEach(section => {
      section.content = 'Not available.';
      section.isAvailable = false;
    });
  }

  return sections;
}

/**
 * Parse MSDS sections using regex patterns
 * This is the core parsing logic that extracts sections from raw OCR text
 */
function parseMSDSSectionsWithRegex(text: string): Array<{sectionNumber: number, content: string}> {
  const sections: Array<{sectionNumber: number, content: string}> = [];
  
  // Debug: Log the first 500 characters of the text to see what we're working with
  console.log('üìã REGEX MSDS PARSER: First 500 characters of text:', text.substring(0, 500));
  
  // Define section patterns - these match the actual section headers in the OCR text
  // Using simpler patterns that match the exact format from the OCR text
  const sectionPatterns = [
    { number: 1, pattern: /##\s*Section\s*1\s*[-\.]\s*Identification\s+of\s+the\s+material\s+and\s+supplier/gi },
    { number: 2, pattern: /##\s*Section\s*2\s*[-\.]\s*Hazards\s+identification/gi },
    { number: 3, pattern: /##\s*Section\s*3\s*[-\.]\s*Composition\/information\s+on\s+ingredients/gi },
    { number: 4, pattern: /##\s*Section\s*4\s*[-\.]\s*First[- ]?aid\s+measures/gi },
    { number: 5, pattern: /##\s*Section\s*5\s*[-\.]\s*Firefighting\s+Measures/gi },
    { number: 6, pattern: /##\s*Section\s*6\s*[-\.]\s*Accidental\s+release\s+measures/gi },
    { number: 7, pattern: /##\s*Section\s*7\s*[-\.]\s*Handling\s+and\s+Storage/gi },
    { number: 8, pattern: /##\s*Section\s*8\s*[-\.]\s*Exposure\s+Controls\s*\/\s*Personal\s+Protection/gi },
    { number: 9, pattern: /##\s*Section\s*9\s*[-\.]\s*Physical\s+and\s+Chemical\s+Properties/gi },
    { number: 10, pattern: /##\s*Section\s*10\s*[-\.]\s*Stability\s+and\s+Reactivity/gi },
    { number: 11, pattern: /##\s*Section\s*11\s*[-\.]\s*Toxicological\s+Information/gi },
    { number: 12, pattern: /##\s*Section\s*12\s*[-\.]\s*Ecological\s+Information/gi },
    // Be tolerant for Section 13 variants: "Disposal", "Disposal considerations", different separators, etc.
    { number: 13, pattern: /##\s*Section\s*13\s*[-.:)\]]\s*Disposal(?:\s+Considerations)?/gi },
    { number: 14, pattern: /##\s*Section\s*14\s*[-\.]\s*Transport\s+Information/gi },
    { number: 15, pattern: /##\s*Section\s*15\s*[-\.]\s*Regulatory\s+Information/gi },
    { number: 16, pattern: /##\s*Section\s*16\s*[-\.]\s*Other\s+Information/gi }
  ];
  
  // Find all section headers and their positions
  const sectionMatches: Array<{number: number, start: number, end: number}> = [];
  
  sectionPatterns.forEach(({ number, pattern }) => {
    // Reset the regex lastIndex to ensure proper matching
    pattern.lastIndex = 0;
    const match = pattern.exec(text);
    if (match) {
      console.log(`üìã REGEX MSDS PARSER: Found Section ${number} at position ${match.index}`);
      sectionMatches.push({
        number,
        start: match.index,
        end: match.index + match[0].length
      });
    } else {
      console.log(`üìã REGEX MSDS PARSER: Section ${number} not found`);
    }
  });
  
  // Sort by position
  sectionMatches.sort((a, b) => a.start - b.start);
  
  // Extract content for each section
  sectionMatches.forEach((match, index) => {
    const nextMatch = sectionMatches[index + 1];
    const startPos = match.end;
    const endPos = nextMatch ? nextMatch.start : text.length;
    
    let content = text.substring(startPos, endPos).trim();
    
    // Clean up the content
    content = isParserV2() ? cleanSectionContentV2(content) : cleanSectionContent(content);
    
    if (content.length > 20) {
      sections.push({
        sectionNumber: match.number,
        content: content
      });
    }
  });
  
  console.log(`üìã REGEX MSDS PARSER: Found ${sections.length} sections with content`);

  return sections;
}

/**
 * Detect MSDS section headers using pattern matching
 */
function detectMSDSHeader(line: string): { sectionNumber: number; title: string } | null {
  for (let i = 0; i < MSDS_HEADER_PATTERNS.length; i++) {
    const pattern = MSDS_HEADER_PATTERNS[i];
    const match = line.match(pattern);
    
    if (match) {
      // Determine section number based on pattern index
      let sectionNumber: number;
      let title: string;
      
      if (i < 16) {
        // First 16 patterns are basic markdown format numbered sections
        sectionNumber = i + 1;
        title = match[2] || match[1] || line;
      } else if (i < 32) {
        // Next 16 patterns are detailed markdown format numbered sections
        const detailedPatternIndex = i - 16;
        sectionNumber = detailedPatternIndex + 1;
        title = match[2] || match[1] || line;
      } else if (i < 48) {
        // Next 16 patterns are exact OCR format numbered sections
        const exactPatternIndex = i - 32;
        sectionNumber = exactPatternIndex + 1;
        title = match[1] || line;
      } else if (i < 64) {
        // Next 16 patterns are without ## prefix numbered sections
        const noPrefixPatternIndex = i - 48;
        sectionNumber = noPrefixPatternIndex + 1;
        title = match[1] || line;
      } else if (i < 80) {
        // Next 16 patterns are traditional format numbered sections
        const traditionalPatternIndex = i - 64;
        sectionNumber = traditionalPatternIndex + 1;
        title = match[2] || match[1] || line;
      } else {
        // Last 16 patterns are direct headings - need to map to section numbers
        const directPatternIndex = i - 80;
        sectionNumber = directPatternIndex + 1;
        title = match[1] || line;
      }
      
      return { sectionNumber, title: title.trim() };
    }
  }
  
  return null;
}

/**
 * Clean section content by removing basic formatting and normalizing whitespace
 * SIMPLIFIED: Much less aggressive cleaning to preserve important content
 */
function cleanSectionContent(content: string): string {
  if (!content || content.trim().length === 0) {
    return '';
  }

  let cleaned = content;

  // Basic LaTeX cleaning - only remove obvious LaTeX formatting
  cleaned = cleaned
    .replace(/\\beta/g, 'Œ≤')
    .replace(/\\rightarrow/g, '‚Üí')
    .replace(/\\geqslant/g, '‚â•')
    .replace(/\\leqslant/g, '‚â§')
    .replace(/\\quad/g, ' ')
    .replace(/\\left\(/g, '(')
    .replace(/\\right\)/g, ')')
    .replace(/\\mathrm\{([^}]+)\}/g, '$1')
    .replace(/\$([^$]+)\$/g, '$1') // Remove LaTeX math formatting like $9067-32-7$
    .replace(/\\[a-zA-Z]+/g, '') // Remove remaining LaTeX commands
    .replace(/\{([^}]+)\}/g, '$1') // Remove remaining braces
    .trim();

  // Remove only obvious section headers (not content)
  cleaned = cleaned
    .replace(/^#+\s*Section\s+\d+[^#]*$/gmi, '') // Remove section headers like "## Section 1 - Title"
    .replace(/^#+\s*\d+\.\s*[^#\n]*$/gm, '') // Remove numbered headers like "### 1.1 Title" (single line only)
    .replace(/^#{1,6}\s*/gm, '') // Remove markdown header symbols
    .trim();

  // Basic markdown cleaning
  cleaned = cleaned
    .replace(/\*\*([^*]+)\*\*/g, '$1') // Remove bold formatting
    .replace(/\*([^*]+)\*/g, '$1') // Remove italic formatting
    .replace(/`([^`]+)`/g, '$1') // Remove code formatting
    .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1') // Remove markdown links
    .trim();

  // Normalize whitespace but preserve line breaks
  cleaned = cleaned
    .replace(/[ \t]+/g, ' ') // Multiple spaces/tabs to single space
    .replace(/\n\s*\n\s*\n/g, '\n\n') // Multiple newlines to double newline
    .trim();

  return cleaned;
}

/**
 * Clean section content using V2 approach (behind feature flag)
 * More conservative and deterministic cleaning
 */
function cleanSectionContentPhase5(text: string): string {
  return (text || "")
    .replace(/\r\n/g, "\n")
    .replace(/={3,}/g, " ")
    .replace(/\*{3,}/g, " ")
    .replace(/_{3,}/g, " ")
    .replace(/\s{2,}/g, " ")
    .replace(/\n{3,}/g, "\n\n")
    .trim();
}

function cleanSectionContentV2(text: string): string {
  let out = normalizeEOL(text);
  
  // Minimal content cleaning - preserve content, remove only obvious junk
  // Collapse excessive blank lines
  out = out.replace(/\n{3,}/g, '\n\n');
  
  // Remove OCR junk patterns
  out = out.replace(/={3,}/g, '') // Remove === lines
           .replace(/\*{3,}/g, '') // Remove *** lines  
           .replace(/_{3,}/g, '') // Remove ___ lines
           .replace(/\.{3,}/g, '') // Remove ... lines
           .replace(/[-=]{5,}/g, ''); // Remove separator lines
  
  // Basic HTML/markdown cleanup
  out = out.replace(/<br\s*\/?>/gi, '\n')
           .replace(/\*\*(.*?)\*\*/g, '$1')
           .replace(/__([^_]+)__/g, '$1')
           .replace(/`{1,3}[^`]*`{1,3}/g, '');
  
  // LaTeX cleanup
  out = out.replace(/\$\s*/g, '')
           .replace(/\\mathrm\{([^}]+)\}/g, '$1')
           .replace(/\\left\(|\\right\)/g, '')
           .replace(/\\quad|\\beta|\\rightarrow/gi, ' ');
  
  // Normalize "No data available" phrases (preserve them)
  out = normalizeNoData(out);
  
  // Apply Phase 5 minimal cleanup polish
  out = cleanSectionContentPhase5(out);
  
  return out;
}

/**
 * Extract product identifiers from MSDS text
 */
function extractProductIdentifiers(text: string): { productName?: string; inciName?: string; casNumber?: string } {
  const identifiers: { productName?: string; inciName?: string; casNumber?: string } = {};

  // Extract product name
  const productNameMatch = text.match(/(?:product\s+name|product\s+identifier|chemical\s+name)[:\s]+([^\n\r]+)/i);
  if (productNameMatch) {
    identifiers.productName = productNameMatch[1].trim();
  }

  // Extract INCI name
  const inciMatch = text.match(/(?:inci\s+name|inci)[:\s]+([^\n\r]+)/i);
  if (inciMatch) {
    identifiers.inciName = inciMatch[1].trim();
  }

  // Extract CAS number
  const casMatch = text.match(/(?:cas\s+number|cas\s+no|cas)[:\s]+(\d{2,7}-\d{2}-\d)/i);
  if (casMatch) {
    identifiers.casNumber = casMatch[1].trim();
  }

  return identifiers;
}

/**
 * Process MSDS sections with AI enhancement if needed
 */
async function processMSDSSections(sections: MSDSSection[], apiKey: string): Promise<MSDSSection[]> {
  // For now, return sections as-is
  // Future enhancement: Use AI to improve content quality, fix formatting, etc.
  
  console.log('üìã MSDS: Processing sections with AI enhancement...');
  
  // Log section processing results
  sections.forEach(section => {
    if (section.isAvailable) {
      console.log(`‚úÖ MSDS: Section ${section.sectionNumber} - ${section.title}: ${section.content.length} characters`);
    } else {
      console.log(`‚ùå MSDS: Section ${section.sectionNumber} - ${section.title}: Not available`);
    }
  });

  return sections;
}

/**
 * Generate MSDS template placeholders for NTCB template
 */
export function generateMSDSTemplatePlaceholders(): string[] {
  const placeholders: string[] = [];
  
  // Generate placeholders for each section using simple field names (like COA/TDS)
  for (let i = 1; i <= 16; i++) {
    const sectionKey = `msds_s${i}`;
    placeholders.push(sectionKey);
  }
  
  // Add product identifier placeholders with simple field names
  placeholders.push('msds_product_name');
  placeholders.push('msds_inci_name');
  placeholders.push('msds_cas_number');
  
  return placeholders;
}

/**
 * Map MSDS sections to template placeholders
 * Uses simple field names that match template placeholders (like COA/TDS)
 */
export function mapMSDSSectionsToTemplate(sections: MSDSSection[], productIdentifiers: any): Record<string, string> {
  const templateData: Record<string, string> = {};
  
  // Map sections to simple field names that match template placeholders
  sections.forEach(section => {
    // Use simple field names like COA/TDS: msds_s1, msds_s2, etc.
    const placeholderKey = `msds_s${section.sectionNumber}`;
    templateData[placeholderKey] = section.content;
  });
  
  // Map product identifiers with simple field names
  if (productIdentifiers.productName) {
    templateData['msds_product_name'] = productIdentifiers.productName;
  }
  if (productIdentifiers.inciName) {
    templateData['msds_inci_name'] = productIdentifiers.inciName;
  }
  if (productIdentifiers.casNumber) {
    templateData['msds_cas_number'] = productIdentifiers.casNumber;
  }
  
  return templateData;
}

/**
 * Generate structured JSON format for MSDS sections
 * This creates the exact JSON format requested by the user
 */
export function generateMSDSStructuredJSON(sections: MSDSSection[]): any {
  const msdsSections = sections.map(section => {
    // Get the full section title
    const sectionTitles = [
      "Section 1 - Identification of the material and supplier",
      "Section 2 - Hazards identification", 
      "Section 3 - Composition/information on ingredients",
      "Section 4 - First-aid measures",
      "Section 5 - Firefighting measures",
      "Section 6 - Accidental release measures",
      "Section 7 - Handling and storage",
      "Section 8 - Exposure controls/personal protection",
      "Section 9 - Physical and chemical properties",
      "Section 10 - Stability and reactivity",
      "Section 11 - Toxicological information",
      "Section 12 - Ecological information",
      "Section 13 - Disposal considerations",
      "Section 14 - Transport information",
      "Section 15 - Regulatory information",
      "Section 16 - Other information"
    ];
    
    return {
      "Section": sectionTitles[section.sectionNumber - 1] || `Section ${section.sectionNumber}`,
      "SectionContent": section.isAvailable ? section.content : "Not available."
    };
  });
  
  return {
    "MSDS": msdsSections
  };
}

/**
 * Generate intelligent field mapping for MSDS documents
 * Maps MSDS sections to template placeholders in the correct order
 */
export function generateMSDSIntelligentMapping(sections: MSDSSection[]): (string | null)[] {
  // Create a mapping array with 16 positions (for 16 MSDS sections)
  const mapping: (string | null)[] = new Array(16).fill(null);
  
  // Map each section to its corresponding position
  sections.forEach(section => {
    if (section.sectionNumber >= 1 && section.sectionNumber <= 16) {
      const fieldName = `msds_s${section.sectionNumber}`;
      mapping[section.sectionNumber - 1] = fieldName; // Convert to 0-based index
    }
  });
  
  console.log('üéØ Generated MSDS intelligent mapping:', mapping);
  return mapping;
}

/**
 * Filter out headers and footers from OCR text using AI
 */
async function filterHeadersAndFooters(text: string, apiKey: string): Promise<string> {
  try {
    const config = loadConfig();
    const llmModel = config.apiSettings.llmModel || 'mistral-large-latest';
    
    const prompt = `
You are an expert in document analysis. Your task is to identify and remove headers and footers from a document while preserving the main content.

DOCUMENT TEXT:
${text}

INSTRUCTIONS:
1. Identify and REMOVE headers (typically at the top of the document) that contain:
   - Company names, logos, or branding
   - Document titles or headers that are repeated
   - Navigation elements
   - Page numbers at the top

2. Identify and REMOVE footers (typically at the bottom of the document) that contain:
   - Company contact information (addresses, phone numbers, emails)
   - Copyright notices
   - Page numbers at the bottom
   - Legal disclaimers
   - Website URLs
   - Repeated company information
   - Chinese text with contact details (ÁîµËØù, ‰º†Áúü, ÈÇÆÁÆ±, Âú∞ÂùÄ, etc.)
   - Company names in multiple languages
   - Any text that appears to be repeated company branding
   - Lines containing "Tel:", "Fax:", "Email:", "Add:", "Web:", "www."
   - Lines with Chinese characters followed by English translations
   - Company addresses and contact details

3. SPECIFICALLY REMOVE these patterns:
   - Lines containing phone numbers, fax numbers, email addresses
   - Lines containing website URLs (www., .com, .cn, etc.)
   - Lines containing company addresses
   - Chinese text mixed with English contact information
   - Lines that appear to be company branding or contact details

4. Preserve ALL main document content including:
   - Section headings (1. Identification, 2. Hazards, etc.)
   - Technical specifications and data
   - Tables and structured information
   - Any content that appears to be the main document body
   - Safety information and technical data
   - Section 1 content (product identifiers, supplier information, etc.)
   - Product names, CAS numbers, and chemical identifiers

5. Be AGGRESSIVE in removing contact information and company branding
6. If you see Chinese characters mixed with contact details, remove those lines
7. Remove any lines that look like company contact information, even if they appear in the middle

Return ONLY the cleaned text with headers and footers removed. Do not include any explanations or comments.
`;

    const response = await fetch('https://api.mistral.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: llmModel,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.1,
        max_tokens: 4000
      })
    });

    if (!response.ok) {
      console.error('Header/footer filtering API error:', response.status, response.statusText);
      // Return original text if filtering fails
      return text;
    }

    const result = await response.json();
    const filteredText = result.choices?.[0]?.message?.content?.trim();
    
    if (!filteredText) {
      console.warn('No filtered text returned from AI, using original text');
      return text;
    }
    
    console.log(`üìä Header/footer filtering: ${text.length} ‚Üí ${filteredText.length} characters`);
    
    // Additional regex-based cleanup for common footer patterns
    let additionalCleanup = applyRegexFooterCleanup(filteredText);
    console.log(`üìä Additional regex cleanup: ${filteredText.length} ‚Üí ${additionalCleanup.length} characters`);
    
    // Apply V2 cleanup utilities if feature flag is enabled
    if (isParserV2()) {
      additionalCleanup = removeRepeatedFooters(additionalCleanup);
      additionalCleanup = normalizeEOL(additionalCleanup);
      console.log(`üìä V2 cleanup applied: ${additionalCleanup.length} characters`);
    }
    
    return additionalCleanup;
    
  } catch (error) {
    console.error('Header/footer filtering error:', error);
    // Return original text if filtering fails
    return text;
  }
}

/**
 * Apply regex-based cleanup for common footer patterns
 */
function applyRegexFooterCleanup(text: string): string {
  let cleanedText = text;
  
  // Remove lines containing Chinese characters mixed with contact info
  cleanedText = cleanedText.replace(/^.*[\u4e00-\u9fff].*(?:Tel|Fax|Email|Add|Web|www|@).*$/gm, '');
  
  // Remove lines containing phone numbers, fax, email patterns
  cleanedText = cleanedText.replace(/^.*(?:Tel|Fax|Email|ÁîµËØù|‰º†Áúü|ÈÇÆÁÆ±).*$/gm, '');
  
  // Remove lines containing website URLs
  cleanedText = cleanedText.replace(/^.*(?:www\.|\.com|\.cn|\.org).*$/gm, '');
  
  // Remove lines containing addresses (Add:, Âú∞ÂùÄ)
  cleanedText = cleanedText.replace(/^.*(?:Add:|Âú∞ÂùÄ).*$/gm, '');
  
  // Remove lines with Chinese company names followed by English
  cleanedText = cleanedText.replace(/^.*[\u4e00-\u9fff].*<br>.*$/gm, '');
  
  // Remove lines containing only Chinese characters (likely company names)
  cleanedText = cleanedText.replace(/^[\u4e00-\u9fff\s]+$/gm, '');
  
  // Remove lines with mixed Chinese and English contact details
  cleanedText = cleanedText.replace(/^.*[\u4e00-\u9fff].*[A-Za-z].*$/gm, '');
  
  // Clean up multiple empty lines
  cleanedText = cleanedText.replace(/\n\s*\n\s*\n/g, '\n\n');
  
  return cleanedText.trim();
}




/* ======================================================
 *  VERBATIM MODE (format-agnostic, supplier-exact output)
 *  ======================================================
 *  This block adds a minimal, safe parsing path that:
 *   - preserves supplier text verbatim (no normalization),
 *   - supports multiple heading styles,
 *   - maps to the canonical 16 template keys,
 *   - concatenates duplicate sections instead of overwriting.
 */

/** Canonical 16-section keys (exactly as in the Word template) */
const TEMPLATE_KEYS_VERBATIM: Record<number, string> = {
  1:'1. Identification of the material and supplier:',
  2:'2. Hazards Identification:',
  3:'3. Composition/ Information on Ingredients:',
  4:'4. First aid measures',
  5:'5. Firefighting measures:',
  6:'6. Accidental release measures:',
  7:'7. Handling and storage:',
  8:'8. Exposure controls Appropriate Engineering Controls:',
  9:'9. Physical and Chemical Properties:',
  10:'10. Stability and reactivity',
  11:'11. Toxicological information',
  12:'12. ECOLOGICAL INFORMATION:',
  13:'13. Disposal considerations',
  14:'14. Transport Information:',
  15:'15. Regulatory Information:',
  16:'16. Other Information:'
};

/** Multi-pattern heading detection (covers SECTION n:, "* n Title", "n. Title", ALLCAPS title) */
type HeadingHitVerbatim = { start: number; end: number; raw: string; num?: number; title: string };
const HEADING_PATTERNS_VERBATIM: RegExp[] = [
  // "## Section 4 ‚Äî ‚Ä¶" (accepts up to three leading `#` and the em dash `‚Äî`)
  /^\s{0,3}#{0,3}\s*section\s+(\d{1,2})\s*[-‚Äì‚Äî:.)]\s*(.+)$/gmi,
  
  // "## 1 Identification" / "* 1 ‚Ä¶"
  /^\s{0,3}#{0,3}\s*[*‚Ä¢]?\s*(\d{1,2})\s+([A-Z].+)$/gmi,
  
  // "## 9. Physical ‚Ä¶" (not 9.1)
  /^\s{0,3}#{0,3}\s*(\d{1,2})(?:\.(?!\d)|[)\]:\-‚Äì‚Äî.]\s+|\s+)(.+)$/gmi,
  
  // ALLCAPS fallback
  /^\s{0,3}#{0,3}\s*([A-Z][A-Z \-/]{6,})$/gmi
];

function collectHeadingsVerbatim(fullText: string): HeadingHitVerbatim[] {
  const hits: HeadingHitVerbatim[] = [];
  for (const rx of HEADING_PATTERNS_VERBATIM) {
    rx.lastIndex = 0;
    let m: RegExpExecArray | null;
    while ((m = rx.exec(fullText)) !== null) {
      if (m.length === 3) {
        const num = parseInt(m[1], 10);
        hits.push({ start: m.index, end: m.index + m[0].length, raw: m[0], num, title: (m[2] || '').trim() });
      } else if (m.length === 2) {
        hits.push({ start: m.index, end: m.index + m[0].length, raw: m[0], title: (m[1] || '').trim() });
      }
    }
  }
  // de-dupe: keep the longest token at a given start index
  hits.sort((a,b)=> a.start - b.start || b.raw.length - a.raw.length);
  const dedup: HeadingHitVerbatim[] = [];
  let lastStart = -1;
  for (const h of hits) {
    if (h.start !== lastStart) { dedup.push(h); lastStart = h.start; }
  }
  
  // DEBUG: Log found headings
  console.log('üîç VERBATIM headings found:');
  for (const h of dedup) {
    console.log(`  [${h.start}] #${h.num ?? '?'} "${h.title}" (raw: "${h.raw}")`);
  }
  
  return dedup;
}

/** Title synonym map for fuzzy mapping when a heading lacks a number */
const TITLE_SYNONYMS_VERBATIM: Record<number, string[]> = {
  1: ["identification","identification of the substance","identification of product","company/undertaking","supplier"],
  2: ["hazard","hazards identification","hazard(s) identification","ghs","hmis","nfpa"],
  3: ["composition","information on ingredients","composition/information on ingredients","ingredients"],
  4: ["first aid","first-aid measures","first aid measures"],
  5: ["firefighting","fire-fighting","fire fighting","extinguishing"],
  6: ["accidental release","spill","accidental release measures"],
  7: ["handling and storage","storage conditions","precautions for safe handling"],
  8: ["exposure controls","personal protection","exposure controls/personal protection","oel","ppe"],
  9: ["physical and chemical properties","appearance","ph","flash point","boiling","melting"],
  10:["stability and reactivity","incompatible","decomposition"],
  11:["toxicological information","acute toxicity","irritation","sensitization"],
  12:["ecological information","aquatic","bioaccumulative","pbt","vpvb"],
  13:["disposal considerations","waste treatment","waste disposal"],
  14:["transport information","un number","adr","iata","imdg","packing group","transport"],
  15:["regulatory information","reach","tsca","sara","regulatory"],
  16:["other information","abbreviations","revision","date of preparation","other information"]
};

function normalizeHeadingTitleVerbatim(s: string): string {
  return s.toLowerCase().replace(/[^a-z0-9 ]+/g,' ').replace(/\s+/g,' ').trim();
}

function diceVerbatim(a: string, b: string): number {
  const bi = (s: string) => {
    const out: string[] = [];
    for (let i=0;i<s.length-1;i++) out.push(s.slice(i,i+2));
    return out;
  };
  const A = bi(a), B = bi(b);
  const multiset = new Map<string, number>();
  for (const x of A) multiset.set(x, (multiset.get(x)||0)+1);
  let inter = 0;
  for (const y of B) {
    const c = multiset.get(y) || 0;
    if (c>0) { inter++; multiset.set(y, c-1); }
  }
  return A.length + B.length ? (2*inter)/(A.length+B.length) : 0;
}

function resolveSectionNumberFromTitleVerbatim(title: string): number | null {
  const t = normalizeHeadingTitleVerbatim(title);
  let best = { n: 0, score: 0 };
  for (const n of Object.keys(TITLE_SYNONYMS_VERBATIM).map(Number)) {
    for (const syn of TITLE_SYNONYMS_VERBATIM[n]) {
      const s = diceVerbatim(t, normalizeHeadingTitleVerbatim(syn));
      if (s > best.score) best = { n, score: s };
    }
  }
  return best.score >= 0.6 ? best.n : null;
}

type SectionBlockVerbatim = { number: number; content: string };

/** Slice verbatim content between consecutive headings; append duplicates */
function sliceSectionsVerbatim(fullText: string, headings: HeadingHitVerbatim[]): SectionBlockVerbatim[] {
  const withNums = headings.map(h => (h.num ? h : { ...h, num: resolveSectionNumberFromTitleVerbatim(h.title) || undefined }))
                           .filter(h => h.num && h.num>=1 && h.num<=16) as Required<HeadingHitVerbatim>[];

  withNums.sort((a,b)=> a.start - b.start);

  const blocks: SectionBlockVerbatim[] = [];
  for (let i=0;i<withNums.length;i++) {
    const cur = withNums[i];
    const nextStart = i+1 < withNums.length ? withNums[i+1].start : fullText.length;
    const content = fullText.slice(cur.end, nextStart).trim();
    blocks.push({ number: cur.num, content });
  }

  // Merge duplicates by appending
  const map = new Map<number, string>();
  for (const b of blocks) {
    const prev = map.get(b.number);
    map.set(b.number, prev ? (prev + '\\n\\n' + b.content) : b.content);
  }

  return Array.from(map.entries()).sort((a,b)=>a[0]-b[0]).map(([number, content]) => ({ number, content }));
}


/** Public: split to MSDSSection[] with exact supplier text */
export function splitSectionsVerbatim(raw: string): MSDSSection[] {
  const fullText = preCleanVerbatim(raw);
  const headings = collectHeadingsVerbatim(fullText);
  
  // DEBUG: Log detected headings
  console.log('VERBATIM headings:');
  for (const h of headings) console.log(`[${h.start}] #${h.num ?? '?'} ${h.title}`);
  
  if (headings.length === 0) {
    // If nothing matched, dump everything into section 1 to avoid data loss
    return [{
      sectionNumber: 1,
      title: TEMPLATE_KEYS_VERBATIM[1],
      content: fullText.trim(),
      isAvailable: !!fullText.trim()
    }];
  }
  const blocks = sliceSectionsVerbatim(fullText, headings);
  
  // DEBUG: Log section blocks
  for (const b of blocks) {
    console.log(`SEC ${b.number} -> ${b.content.slice(0, 80).replace(/\n/g,' ')}`);
  }
  const sections: MSDSSection[] = [];
  const seen = new Set<number>();
  for (const b of blocks) {
    sections.push({
      sectionNumber: b.number,
      title: TEMPLATE_KEYS_VERBATIM[b.number],
      content: b.content,
      isAvailable: !!b.content
    });
    seen.add(b.number);
  }
  // Ensure all 16 keys exist (empty if missing)
  for (let i=1;i<=16;i++) {
    if (!seen.has(i)) {
      sections.push({
        sectionNumber: i,
        title: TEMPLATE_KEYS_VERBATIM[i],
        content: '',
        isAvailable: false
      });
    }
  }
  // sort by number
  sections.sort((a,b)=>a.sectionNumber-b.sectionNumber);
  
  // DEBUG: Log section content preview
  console.log('üîç VERBATIM section previews:');
  for (const s of sections) {
    const preview = s.content.slice(0, 80).replace(/\n/g, ' ');
    console.log(`  SEC ${s.sectionNumber} -> "${preview}${s.content.length > 80 ? '...' : ''}"`);
  }
  
  return sections;
}

/** Public: emit JSON with canonical template keys ‚Üí verbatim content */
export function generateMSDSStructuredJSONVerbatim(sections: MSDSSection[]): Record<string,string> {
  const out: Record<string,string> = {};
  for (let i=1;i<=16;i++) out[TEMPLATE_KEYS_VERBATIM[i]] = '';
  for (const s of sections) {
    const key = TEMPLATE_KEYS_VERBATIM[s.sectionNumber];
    const val = (s.content || '').trim();
    if (!val) continue;
    out[key] = out[key] ? (out[key] + '\\n\\n' + val) : val;
  }
  return out;
}

/** Verbatim header/footer removal - edge+frequency only */
export function removePageRecurringHeadersAndFootersVerbatim(raw: string, topN = 10, bottomN = 10): string {
  const pages = splitIntoPagesVerbatim(raw);
  if (!pages.length) return preCleanVerbatim(raw);

  const minRepeat = Math.max(2, Math.ceil(pages.length * 0.6)); // ‚â•60% of pages
  const minFpLen = 18;

  const topCounts = new Map<string, number>();
  const bottomCounts = new Map<string, number>();
  const topFPsByPage: string[][] = [];
  const bottomFPsByPage: string[][] = [];

  for (const p of pages) {
    const top = p.lines.slice(0, Math.min(topN, p.lines.length)).map(fpLine);
    const bottom = p.lines.slice(Math.max(0, p.lines.length - bottomN)).map(fpLine);
    topFPsByPage.push(top); bottomFPsByPage.push(bottom);
    for (const fp of top) topCounts.set(fp, (topCounts.get(fp) || 0) + 1);
    for (const fp of bottom) bottomCounts.set(fp, (bottomCounts.get(fp) || 0) + 1);
  }

  const dropTop = new Set(Array.from(topCounts.entries()).filter(([fp, c]) => fp && fp.length >= minFpLen && c >= minRepeat).map(([fp]) => fp));
  const dropBottom = new Set(Array.from(bottomCounts.entries()).filter(([fp, c]) => fp && fp.length >= minFpLen && c >= minRepeat).map(([fp]) => fp));

  console.log(`üßπ VERBATIM Header/Footer removal: Found ${dropTop.size} top patterns, ${dropBottom.size} bottom patterns to remove`);

  const firstSeen = new Set<string>();
  const cleanedPages: string[] = [];

  pages.forEach((page, pIdx) => {
    const L = page.lines.length;
    const topSet = new Set(topFPsByPage[pIdx]);
    const bottomSet = new Set(bottomFPsByPage[pIdx]);
    const keep: string[] = [];

    for (let i = 0; i < L; i++) {
      const line = page.lines[i];
      const fp = fpLine(line);
      const topCand = i < Math.min(topN, L) && topSet.has(fp);
      const botCand = i >= Math.max(0, L - bottomN) && bottomSet.has(fp);

      let drop = false;
      if ((topCand && dropTop.has(fp)) || (botCand && dropBottom.has(fp))) {
        if (!looksLikeMaterialFact(line)) {
          if (!firstSeen.has(fp)) { 
            firstSeen.add(fp); 
            drop = false; // keep first occurrence (for Sec 1)
            console.log(`üìå VERBATIM Keeping first occurrence: ${line.trim().substring(0, 50)}...`);
          } else { 
            drop = true;
            console.log(`üóëÔ∏è VERBATIM Removing repeated: ${line.trim().substring(0, 50)}...`);
          }
        }
      }
      if (!drop) keep.push(line);
    }
    cleanedPages.push(keep.join('\n').trim());
  });

  const joined = cleanedPages.join('\n\n').replace(/\n{3,}/g, '\n\n').trim();
  const originalLength = (raw.match(/\n/g)?.length ?? 0) + 1;
  const cleanedLength = (joined.match(/\n/g)?.length ?? 0) + 1;
  const removalRatio = (originalLength - cleanedLength) / originalLength;
  
  if (removalRatio > 0.30) {
    console.warn(`‚ö†Ô∏è VERBATIM Header/Footer removal too aggressive (${Math.round(removalRatio * 100)}% removed); reverting to verbatim text.`);
    return preCleanVerbatim(raw);
  }
  
  console.log(`‚úÖ VERBATIM Header/Footer removal: ${Math.round(removalRatio * 100)}% of lines removed`);
  return joined;
}

/** OLD verbatim pipeline - DISABLED to force new 6-step solution */
export function buildVerbatimStructuredJson_DISABLED(rawText: string): Record<string, string> {
  console.log('üö® OLD VERBATIM PIPELINE CALLED - THIS SHOULD NOT HAPPEN!');
  console.log(`üìè Input text length: ${rawText.length} characters`);
  
  // 1) Remove HTML/Markdown artifacts (keep plain text only)
  const plainText = rawText
    .replace(/<br\s*\/?>/gi, '\n')  // <br> ‚Üí newline
    .replace(/<[^>]*>/g, '')        // Remove all other HTML tags
    .replace(/\|\s*:--\s*\|/g, '')  // Remove markdown table separators
    .replace(/\|\s*\|\s*/g, ' ')    // Replace table cell separators with spaces
    .replace(/\|\s*/g, ' ')         // Replace remaining table markers
    .replace(/\s+/g, ' ')           // Normalize whitespace
    .trim();
  console.log(`üìè After HTML/Markdown cleanup: ${plainText.length} characters`);
  
  // 2) Remove page headers/footers (edge+frequency only)
  const cleaned = removePageRecurringHeadersAndFootersVerbatim(plainText);
  console.log(`üìè After header/footer removal: ${cleaned.length} characters`);
  
  // 3) Split into sections using verbatim approach
  const sections = splitSectionsVerbatim(cleaned);
  console.log(`üìã VERBATIM: Found ${sections.length} sections`);
  
  // 3) Generate structured JSON with canonical keys
  const json = generateMSDSStructuredJSONVerbatim(sections);
  
  // 4) Log completeness check
  console.log('üîç VERBATIM Completeness check:');
  for (let i = 1; i <= 16; i++) {
    const key = TEMPLATE_KEYS_VERBATIM[i];
    const content = json[key] || '';
    const status = content.length > 10 ? '‚úÖ' : '‚ùå';
    console.log(`  ${status} Section ${i}: ${content.length} chars`);
  }
  
  console.log('‚úÖ VERBATIM pipeline completed');
  return json;
}
